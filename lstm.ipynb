{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.12 64-bit ('nlp-4650-project': conda)"
    },
    "interpreter": {
      "hash": "140351e719ebabd8c89d647add28ebb80040bf2d1128912b99179fb480ea150d"
    },
    "colab": {
      "name": "lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbhpdgJevlV2"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0F2jtBm5hMp",
        "outputId": "b55a50f0-743d-4dc3-a5aa-b9d89443347e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My\\ Drive/NLP/project"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/My Drive/NLP/project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWCHRlAbvtvn",
        "outputId": "ff94db09-bd60-4915-b14d-ffd96b9c2148"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (3.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.11.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.1.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.11.0)\n",
            "Collecting huggingface\n",
            "  Downloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\n",
            "Collecting transformers>3\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-1.16.1-py3-none-any.whl (298 kB)\n",
            "\u001b[K     |████████████████████████████████| 298 kB 54.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 54.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.0.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (3.2.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.62.3)\n",
            "Collecting bert-score\n",
            "  Downloading bert_score-0.3.10-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 9.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 685 kB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>3->-r requirements.txt (line 8)) (4.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>3->-r requirements.txt (line 8)) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>3->-r requirements.txt (line 8)) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>3->-r requirements.txt (line 8)) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>3->-r requirements.txt (line 8)) (3.4.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 68.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 58.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers>3->-r requirements.txt (line 8)) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>3->-r requirements.txt (line 8)) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 1)) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 4)) (2018.9)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 57.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 9)) (3.0.0)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 77.0 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 73.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 9)) (0.3.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 9)) (0.70.12.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>3->-r requirements.txt (line 8)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>3->-r requirements.txt (line 8)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>3->-r requirements.txt (line 8)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>3->-r requirements.txt (line 8)) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 11)) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 11)) (1.1.0)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 76.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (2.0.8)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 65.2 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 70.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (21.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>3->-r requirements.txt (line 8)) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>3->-r requirements.txt (line 8)) (7.1.2)\n",
            "Installing collected packages: multidict, frozenlist, yarl, pyyaml, asynctest, async-timeout, aiosignal, tokenizers, sacremoses, huggingface-hub, fsspec, aiohttp, xxhash, transformers, huggingface, datasets, bert-score\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 bert-score-0.3.10 datasets-1.16.1 frozenlist-1.2.0 fsspec-2021.11.1 huggingface-0.0.1 huggingface-hub-0.2.1 multidict-5.2.0 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5 xxhash-2.0.2 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24aidOZEzgMe"
      },
      "source": [
        "# Train with No Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5tjwZ5XIf3o",
        "outputId": "8cddbbbb-06ff-40a5-b682-12ef73509077"
      },
      "source": [
        "!python run_lstm.py \\\n",
        "  --username \"elonmusk\" \\\n",
        "  --num-epochs 1 \\\n",
        "  --hidden-size 256 \\\n",
        "  --embedding-dim 256 \\\n",
        "  --n-layers 2 \\\n",
        "  --lr 0.0004 \\\n",
        "  --dropout 0.2 \\\n",
        "  --sequence-length 32"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/My Drive/NLP/project/dataset.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  df = df[filter]\n",
            "[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "Namespace(bos_token='<BOS>', clip=0.25, dropout=0.2, embedding_dim=256, eos_token='<EOS>', eval_every=200, hidden_size=256, length=50, lr=0.0004, n_gpu=1, n_layers=2, no_cuda=False, num_epochs=1, output_dir='outputs', seed=42, sequence_length=32, train_split=0.8, use_pretrained_embeddings=False, username='elonmusk')\n",
            "12/06/2021 04:09:11 - INFO - __main__ -   [Iter 200] Loss 7.82  Val Loss: 8.56  Val Perplexity: 5205.08\n",
            "12/06/2021 04:09:26 - INFO - __main__ -   [Iter 400] Loss 7.22  Val Loss: 8.45  Val Perplexity: 4665.27\n",
            "12/06/2021 04:09:42 - INFO - __main__ -   [Iter 600] Loss 6.81  Val Loss: 8.52  Val Perplexity: 4991.26\n",
            "12/06/2021 04:09:57 - INFO - __main__ -   [Iter 800] Loss 6.48  Val Loss: 9.03  Val Perplexity: 8385.84\n",
            "12/06/2021 04:10:12 - INFO - __main__ -   [Iter 1000] Loss 6.23  Val Loss: 8.67  Val Perplexity: 5824.43\n",
            "12/06/2021 04:10:43 - INFO - __main__ -   [Iter 1400] Loss 6.02  Val Loss: 8.58  Val Perplexity: 5314.72\n",
            "12/06/2021 04:10:58 - INFO - __main__ -   [Iter 1600] Loss 5.91  Val Loss: 8.74  Val Perplexity: 6230.45\n",
            "12/06/2021 04:11:14 - INFO - __main__ -   [Iter 1800] Loss 5.81  Val Loss: 8.61  Val Perplexity: 5481.34\n",
            "12/06/2021 04:11:29 - INFO - __main__ -   [Iter 2000] Loss 5.75  Val Loss: 8.78  Val Perplexity: 6527.43\n",
            "12/06/2021 04:11:44 - INFO - __main__ -   [Iter 2200] Loss 5.72  Val Loss: 8.60  Val Perplexity: 5417.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-p-VcNVk-Wn",
        "outputId": "4753f3f0-9e84-4309-beab-55c84e1f74f2"
      },
      "source": [
        "!python run_lstm_generation.py \\\n",
        "  --username \"elonmusk\" \\\n",
        "  --num_sequences 10 \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --seed 52"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8896])\n",
            "Traceback (most recent call last):\n",
            "  File \"run_lstm_generation.py\", line 233, in <module>\n",
            "    p=args.p,\n",
            "  File \"run_lstm_generation.py\", line 196, in generate_sequences\n",
            "    top_p=p,\n",
            "  File \"run_lstm_generation.py\", line 156, in sample_sequence\n",
            "    input_ids = torch.cat([input_ids, next_tokens], dim=-1)\n",
            "RuntimeError: Tensors must have same number of dimensions: got 2 and 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYVcueb3LxCc",
        "outputId": "d59b893c-02a7-4564-9dd2-266136122249"
      },
      "source": [
        "!python run_lstm.py \\\n",
        "  --username \"karpathy\" \\\n",
        "  --num_epochs 7 \\\n",
        "  --eval_every 2000 \\\n",
        "  --hidden_size 512 \\\n",
        "  --embedding_dim 300 \\\n",
        "  --lr 0.0004"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/My Drive/NLP/project/dataset.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  df = df[filter]\n",
            "[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Namespace(bos_token='<BOS>', dropout=0.2, embedding_dim=300, eos_token='<EOS>', eval_every=2000, hidden_size=512, length=50, lr=0.0004, n_gpu=1, n_layers=1, no_cuda=False, num_epochs=7, output_dir='outputs', seed=42, train_split=0.8, use_pretrained_embeddings=False, username='karpathy')\n",
            "12/03/2021 20:12:33 - INFO - __main__ -   [Iter 2000] Loss 7.13  Val Loss: 7.18  Val Perplexity: 1307.88\n",
            "12/03/2021 20:12:43 - INFO - __main__ -   [Iter 4000] Loss 5.84  Val Loss: 7.27  Val Perplexity: 1429.96\n",
            "12/03/2021 20:12:54 - INFO - __main__ -   [Iter 6000] Loss 5.78  Val Loss: 7.32  Val Perplexity: 1506.93\n",
            "12/03/2021 20:13:04 - INFO - __main__ -   [Iter 8000] Loss 4.68  Val Loss: 7.58  Val Perplexity: 1954.83\n",
            "12/03/2021 20:13:15 - INFO - __main__ -   [Iter 10000] Loss 3.48  Val Loss: 7.91  Val Perplexity: 2714.60\n",
            "12/03/2021 20:13:26 - INFO - __main__ -   [Iter 12000] Loss 3.61  Val Loss: 7.99  Val Perplexity: 2963.74\n",
            "12/03/2021 20:13:36 - INFO - __main__ -   [Iter 14000] Loss 2.63  Val Loss: 8.31  Val Perplexity: 4059.78\n",
            "12/03/2021 20:13:47 - INFO - __main__ -   [Iter 16000] Loss 1.82  Val Loss: 8.66  Val Perplexity: 5744.25\n",
            "12/03/2021 20:13:58 - INFO - __main__ -   [Iter 18000] Loss 1.97  Val Loss: 8.67  Val Perplexity: 5845.69\n",
            "12/03/2021 20:14:08 - INFO - __main__ -   [Iter 20000] Loss 1.36  Val Loss: 9.01  Val Perplexity: 8185.54\n",
            "12/03/2021 20:14:16 - INFO - __main__ -   ***** Eval results *****\n",
            "12/03/2021 20:14:16 - INFO - __main__ -     eval_loss = 9.021451734717376\n",
            "12/03/2021 20:14:16 - INFO - __main__ -     eval_perplexity = 8278.786964023957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ2lgKyJMCut",
        "outputId": "5fd8c666-0c7f-43e0-8861-97d5806ac151"
      },
      "source": [
        "!python run_lstm.py \\\n",
        "  --username \"BarackObama\" \\\n",
        "  --num_epochs 7 \\\n",
        "  --eval_every 2000 \\\n",
        "  --hidden_size 512 \\\n",
        "  --embedding_dim 300 \\\n",
        "  --lr 0.0004"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/My Drive/NLP/project/dataset.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  df = df[filter]\n",
            "[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 6000     /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 13000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Namespace(bos_token='<BOS>', dropout=0.2, embedding_dim=300, eos_token='<EOS>', eval_every=2000, hidden_size=512, length=50, lr=0.0004, n_gpu=1, n_layers=1, no_cuda=False, num_epochs=7, output_dir='outputs', seed=42, train_split=0.8, use_pretrained_embeddings=False, username='BarackObama')\n",
            "12/03/2021 20:14:35 - INFO - __main__ -   [Iter 2000] Loss 5.76  Val Loss: 5.54  Val Perplexity: 253.51\n",
            "12/03/2021 20:14:48 - INFO - __main__ -   [Iter 4000] Loss 5.34  Val Loss: 5.28  Val Perplexity: 196.30\n",
            "12/03/2021 20:15:00 - INFO - __main__ -   [Iter 6000] Loss 5.08  Val Loss: 5.11  Val Perplexity: 165.93\n",
            "12/03/2021 20:15:12 - INFO - __main__ -   [Iter 8000] Loss 4.91  Val Loss: 5.03  Val Perplexity: 153.36\n",
            "12/03/2021 20:15:25 - INFO - __main__ -   [Iter 10000] Loss 4.78  Val Loss: 4.95  Val Perplexity: 141.60\n",
            "12/03/2021 20:15:37 - INFO - __main__ -   [Iter 12000] Loss 3.70  Val Loss: 5.01  Val Perplexity: 149.53\n",
            "12/03/2021 20:15:49 - INFO - __main__ -   [Iter 14000] Loss 3.67  Val Loss: 4.96  Val Perplexity: 142.70\n",
            "12/03/2021 20:16:02 - INFO - __main__ -   [Iter 16000] Loss 3.65  Val Loss: 5.00  Val Perplexity: 149.11\n",
            "12/03/2021 20:16:14 - INFO - __main__ -   [Iter 18000] Loss 3.64  Val Loss: 4.94  Val Perplexity: 139.92\n",
            "12/03/2021 20:16:26 - INFO - __main__ -   [Iter 20000] Loss 3.64  Val Loss: 4.94  Val Perplexity: 140.26\n",
            "12/03/2021 20:16:39 - INFO - __main__ -   [Iter 22000] Loss 2.91  Val Loss: 5.01  Val Perplexity: 150.45\n",
            "12/03/2021 20:16:51 - INFO - __main__ -   [Iter 24000] Loss 2.96  Val Loss: 5.08  Val Perplexity: 160.95\n",
            "12/03/2021 20:17:03 - INFO - __main__ -   [Iter 26000] Loss 2.97  Val Loss: 5.07  Val Perplexity: 158.43\n",
            "12/03/2021 20:17:16 - INFO - __main__ -   [Iter 28000] Loss 3.01  Val Loss: 5.07  Val Perplexity: 159.28\n",
            "12/03/2021 20:17:28 - INFO - __main__ -   [Iter 30000] Loss 3.03  Val Loss: 5.08  Val Perplexity: 161.28\n",
            "12/03/2021 20:17:41 - INFO - __main__ -   [Iter 32000] Loss 3.05  Val Loss: 5.04  Val Perplexity: 154.67\n",
            "12/03/2021 20:17:53 - INFO - __main__ -   [Iter 34000] Loss 2.40  Val Loss: 5.24  Val Perplexity: 189.17\n",
            "12/03/2021 20:18:05 - INFO - __main__ -   [Iter 36000] Loss 2.43  Val Loss: 5.21  Val Perplexity: 183.94\n",
            "12/03/2021 20:18:18 - INFO - __main__ -   [Iter 38000] Loss 2.48  Val Loss: 5.19  Val Perplexity: 180.10\n",
            "12/03/2021 20:18:30 - INFO - __main__ -   [Iter 40000] Loss 2.52  Val Loss: 5.24  Val Perplexity: 188.28\n",
            "12/03/2021 20:18:43 - INFO - __main__ -   [Iter 42000] Loss 2.56  Val Loss: 5.20  Val Perplexity: 180.45\n",
            "12/03/2021 20:18:55 - INFO - __main__ -   [Iter 44000] Loss 1.94  Val Loss: 5.34  Val Perplexity: 208.94\n",
            "12/03/2021 20:19:07 - INFO - __main__ -   [Iter 46000] Loss 2.01  Val Loss: 5.42  Val Perplexity: 224.76\n",
            "12/03/2021 20:19:20 - INFO - __main__ -   [Iter 48000] Loss 2.05  Val Loss: 5.39  Val Perplexity: 219.65\n",
            "12/03/2021 20:19:32 - INFO - __main__ -   [Iter 50000] Loss 2.10  Val Loss: 5.39  Val Perplexity: 220.07\n",
            "12/03/2021 20:19:44 - INFO - __main__ -   [Iter 52000] Loss 2.13  Val Loss: 5.35  Val Perplexity: 211.11\n",
            "12/03/2021 20:19:57 - INFO - __main__ -   [Iter 54000] Loss 1.66  Val Loss: 5.42  Val Perplexity: 226.72\n",
            "12/03/2021 20:20:09 - INFO - __main__ -   [Iter 56000] Loss 1.63  Val Loss: 5.49  Val Perplexity: 242.89\n",
            "12/03/2021 20:20:22 - INFO - __main__ -   [Iter 58000] Loss 1.69  Val Loss: 5.54  Val Perplexity: 254.47\n",
            "12/03/2021 20:20:34 - INFO - __main__ -   [Iter 60000] Loss 1.73  Val Loss: 5.58  Val Perplexity: 264.87\n",
            "12/03/2021 20:20:46 - INFO - __main__ -   [Iter 62000] Loss 1.78  Val Loss: 5.56  Val Perplexity: 259.37\n",
            "12/03/2021 20:20:59 - INFO - __main__ -   [Iter 64000] Loss 1.83  Val Loss: 5.56  Val Perplexity: 259.85\n",
            "12/03/2021 20:21:11 - INFO - __main__ -   [Iter 66000] Loss 1.35  Val Loss: 5.67  Val Perplexity: 290.78\n",
            "12/03/2021 20:21:24 - INFO - __main__ -   [Iter 68000] Loss 1.42  Val Loss: 5.73  Val Perplexity: 307.62\n",
            "12/03/2021 20:21:36 - INFO - __main__ -   [Iter 70000] Loss 1.46  Val Loss: 5.72  Val Perplexity: 304.20\n",
            "12/03/2021 20:21:48 - INFO - __main__ -   [Iter 72000] Loss 1.51  Val Loss: 5.73  Val Perplexity: 307.82\n",
            "12/03/2021 20:22:01 - INFO - __main__ -   [Iter 74000] Loss 1.55  Val Loss: 5.75  Val Perplexity: 313.95\n",
            "12/03/2021 20:22:10 - INFO - __main__ -   ***** Eval results *****\n",
            "12/03/2021 20:22:10 - INFO - __main__ -     eval_loss = 5.712339516089308\n",
            "12/03/2021 20:22:10 - INFO - __main__ -     eval_perplexity = 302.57812726937453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn3VNkzQMFab",
        "outputId": "6984a49e-fa90-4097-e3ce-5cb949829b91"
      },
      "source": [
        "!python run_lstm.py \\\n",
        "  --username \"cnn\" \\\n",
        "  --num_epochs 7 \\\n",
        "  --eval_every 2000 \\\n",
        "  --hidden_size 512 \\\n",
        "  --embedding_dim 300 \\\n",
        "  --lr 0.0004"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/My Drive/NLP/project/dataset.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  df = df[filter]\n",
            "[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 12000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 22000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 29000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Namespace(bos_token='<BOS>', dropout=0.2, embedding_dim=300, eos_token='<EOS>', eval_every=2000, hidden_size=512, length=50, lr=0.0004, n_gpu=1, n_layers=1, no_cuda=False, num_epochs=7, output_dir='outputs', seed=42, train_split=0.8, use_pretrained_embeddings=False, username='cnn')\n",
            "12/03/2021 20:22:42 - INFO - __main__ -   [Iter 2000] Loss 7.38  Val Loss: 7.68  Val Perplexity: 2161.91\n",
            "12/03/2021 20:23:05 - INFO - __main__ -   [Iter 4000] Loss 7.13  Val Loss: 7.42  Val Perplexity: 1663.38\n",
            "12/03/2021 20:23:28 - INFO - __main__ -   [Iter 6000] Loss 6.99  Val Loss: 7.30  Val Perplexity: 1483.95\n",
            "12/03/2021 20:23:51 - INFO - __main__ -   [Iter 8000] Loss 6.87  Val Loss: 7.18  Val Perplexity: 1313.06\n",
            "12/03/2021 20:24:14 - INFO - __main__ -   [Iter 10000] Loss 6.79  Val Loss: 7.15  Val Perplexity: 1276.94\n",
            "12/03/2021 20:24:37 - INFO - __main__ -   [Iter 12000] Loss 6.72  Val Loss: 7.06  Val Perplexity: 1162.32\n",
            "12/03/2021 20:25:00 - INFO - __main__ -   [Iter 14000] Loss 6.66  Val Loss: 7.02  Val Perplexity: 1116.85\n",
            "12/03/2021 20:25:23 - INFO - __main__ -   [Iter 16000] Loss 6.61  Val Loss: 6.99  Val Perplexity: 1080.75\n",
            "12/03/2021 20:25:46 - INFO - __main__ -   [Iter 18000] Loss 6.57  Val Loss: 6.96  Val Perplexity: 1049.04\n",
            "12/03/2021 20:26:09 - INFO - __main__ -   [Iter 20000] Loss 6.53  Val Loss: 6.93  Val Perplexity: 1018.67\n",
            "12/03/2021 20:26:32 - INFO - __main__ -   [Iter 22000] Loss 6.50  Val Loss: 6.91  Val Perplexity: 1003.95\n",
            "12/03/2021 20:26:55 - INFO - __main__ -   [Iter 24000] Loss 6.47  Val Loss: 6.93  Val Perplexity: 1024.01\n",
            "12/03/2021 20:27:18 - INFO - __main__ -   [Iter 26000] Loss 5.44  Val Loss: 6.95  Val Perplexity: 1046.47\n",
            "12/03/2021 20:27:42 - INFO - __main__ -   [Iter 28000] Loss 5.43  Val Loss: 7.01  Val Perplexity: 1105.53\n",
            "12/03/2021 20:28:05 - INFO - __main__ -   [Iter 30000] Loss 5.47  Val Loss: 7.03  Val Perplexity: 1125.17\n",
            "12/03/2021 20:28:28 - INFO - __main__ -   [Iter 32000] Loss 5.48  Val Loss: 6.99  Val Perplexity: 1082.81\n",
            "12/03/2021 20:28:51 - INFO - __main__ -   [Iter 34000] Loss 5.49  Val Loss: 7.03  Val Perplexity: 1131.69\n",
            "12/03/2021 20:29:14 - INFO - __main__ -   [Iter 36000] Loss 5.51  Val Loss: 7.03  Val Perplexity: 1125.90\n",
            "12/03/2021 20:29:37 - INFO - __main__ -   [Iter 38000] Loss 5.51  Val Loss: 7.01  Val Perplexity: 1110.00\n",
            "12/03/2021 20:30:00 - INFO - __main__ -   [Iter 40000] Loss 5.53  Val Loss: 7.00  Val Perplexity: 1101.81\n",
            "12/03/2021 20:30:23 - INFO - __main__ -   [Iter 42000] Loss 5.55  Val Loss: 7.00  Val Perplexity: 1100.26\n",
            "12/03/2021 20:30:46 - INFO - __main__ -   [Iter 44000] Loss 5.56  Val Loss: 7.03  Val Perplexity: 1127.57\n",
            "12/03/2021 20:31:09 - INFO - __main__ -   [Iter 46000] Loss 5.58  Val Loss: 6.99  Val Perplexity: 1086.81\n",
            "12/03/2021 20:31:33 - INFO - __main__ -   [Iter 48000] Loss 5.59  Val Loss: 7.01  Val Perplexity: 1109.41\n",
            "12/03/2021 20:31:56 - INFO - __main__ -   [Iter 50000] Loss 4.96  Val Loss: 6.99  Val Perplexity: 1080.61\n",
            "12/03/2021 20:32:19 - INFO - __main__ -   [Iter 52000] Loss 4.74  Val Loss: 7.05  Val Perplexity: 1157.09\n",
            "12/03/2021 20:32:42 - INFO - __main__ -   [Iter 54000] Loss 4.77  Val Loss: 7.11  Val Perplexity: 1223.50\n",
            "12/03/2021 20:33:05 - INFO - __main__ -   [Iter 56000] Loss 4.81  Val Loss: 7.12  Val Perplexity: 1231.21\n",
            "12/03/2021 20:33:28 - INFO - __main__ -   [Iter 58000] Loss 4.84  Val Loss: 7.14  Val Perplexity: 1264.12\n",
            "12/03/2021 20:33:51 - INFO - __main__ -   [Iter 60000] Loss 4.87  Val Loss: 7.13  Val Perplexity: 1244.60\n",
            "12/03/2021 20:34:14 - INFO - __main__ -   [Iter 62000] Loss 4.90  Val Loss: 7.15  Val Perplexity: 1271.69\n",
            "12/03/2021 20:34:37 - INFO - __main__ -   [Iter 64000] Loss 4.92  Val Loss: 7.17  Val Perplexity: 1305.75\n",
            "12/03/2021 20:35:00 - INFO - __main__ -   [Iter 66000] Loss 4.95  Val Loss: 7.17  Val Perplexity: 1298.69\n",
            "12/03/2021 20:35:23 - INFO - __main__ -   [Iter 68000] Loss 4.98  Val Loss: 7.16  Val Perplexity: 1282.86\n",
            "12/03/2021 20:35:46 - INFO - __main__ -   [Iter 70000] Loss 5.00  Val Loss: 7.14  Val Perplexity: 1264.82\n",
            "12/03/2021 20:36:10 - INFO - __main__ -   [Iter 72000] Loss 5.03  Val Loss: 7.15  Val Perplexity: 1271.87\n",
            "12/03/2021 20:36:33 - INFO - __main__ -   [Iter 74000] Loss 5.05  Val Loss: 7.14  Val Perplexity: 1260.78\n",
            "12/03/2021 20:36:56 - INFO - __main__ -   [Iter 76000] Loss 4.13  Val Loss: 7.19  Val Perplexity: 1323.05\n",
            "12/03/2021 20:37:19 - INFO - __main__ -   [Iter 78000] Loss 4.16  Val Loss: 7.23  Val Perplexity: 1378.52\n",
            "12/03/2021 20:37:42 - INFO - __main__ -   [Iter 80000] Loss 4.21  Val Loss: 7.26  Val Perplexity: 1427.37\n",
            "12/03/2021 20:38:05 - INFO - __main__ -   [Iter 82000] Loss 4.26  Val Loss: 7.29  Val Perplexity: 1462.48\n",
            "12/03/2021 20:38:28 - INFO - __main__ -   [Iter 84000] Loss 4.32  Val Loss: 7.28  Val Perplexity: 1456.71\n",
            "12/03/2021 20:38:51 - INFO - __main__ -   [Iter 86000] Loss 4.36  Val Loss: 7.29  Val Perplexity: 1461.65\n",
            "12/03/2021 20:39:14 - INFO - __main__ -   [Iter 88000] Loss 4.40  Val Loss: 7.34  Val Perplexity: 1538.03\n",
            "12/03/2021 20:39:37 - INFO - __main__ -   [Iter 90000] Loss 4.44  Val Loss: 7.30  Val Perplexity: 1473.73\n",
            "12/03/2021 20:40:00 - INFO - __main__ -   [Iter 92000] Loss 4.48  Val Loss: 7.32  Val Perplexity: 1504.41\n",
            "12/03/2021 20:40:23 - INFO - __main__ -   [Iter 94000] Loss 4.51  Val Loss: 7.32  Val Perplexity: 1513.12\n",
            "12/03/2021 20:40:46 - INFO - __main__ -   [Iter 96000] Loss 4.54  Val Loss: 7.30  Val Perplexity: 1484.00\n",
            "12/03/2021 20:41:09 - INFO - __main__ -   [Iter 98000] Loss 4.57  Val Loss: 7.30  Val Perplexity: 1474.81\n",
            "12/03/2021 20:41:32 - INFO - __main__ -   [Iter 100000] Loss 3.47  Val Loss: 7.35  Val Perplexity: 1551.98\n",
            "12/03/2021 20:41:55 - INFO - __main__ -   [Iter 102000] Loss 3.73  Val Loss: 7.39  Val Perplexity: 1617.87\n",
            "12/03/2021 20:42:18 - INFO - __main__ -   [Iter 104000] Loss 3.77  Val Loss: 7.41  Val Perplexity: 1651.75\n",
            "12/03/2021 20:42:41 - INFO - __main__ -   [Iter 106000] Loss 3.82  Val Loss: 7.46  Val Perplexity: 1732.00\n",
            "12/03/2021 20:43:04 - INFO - __main__ -   [Iter 108000] Loss 3.88  Val Loss: 7.48  Val Perplexity: 1772.87\n",
            "12/03/2021 20:43:28 - INFO - __main__ -   [Iter 110000] Loss 3.92  Val Loss: 7.48  Val Perplexity: 1771.22\n",
            "12/03/2021 20:43:51 - INFO - __main__ -   [Iter 112000] Loss 3.96  Val Loss: 7.52  Val Perplexity: 1845.21\n",
            "12/03/2021 20:44:14 - INFO - __main__ -   [Iter 114000] Loss 4.01  Val Loss: 7.52  Val Perplexity: 1844.76\n",
            "12/03/2021 20:44:37 - INFO - __main__ -   [Iter 116000] Loss 4.05  Val Loss: 7.49  Val Perplexity: 1791.05\n",
            "12/03/2021 20:45:00 - INFO - __main__ -   [Iter 118000] Loss 4.09  Val Loss: 7.50  Val Perplexity: 1811.92\n",
            "12/03/2021 20:45:23 - INFO - __main__ -   [Iter 120000] Loss 4.12  Val Loss: 7.49  Val Perplexity: 1787.85\n",
            "12/03/2021 20:45:46 - INFO - __main__ -   [Iter 122000] Loss 4.16  Val Loss: 7.51  Val Perplexity: 1829.44\n",
            "12/03/2021 20:46:09 - INFO - __main__ -   [Iter 124000] Loss 4.19  Val Loss: 7.49  Val Perplexity: 1781.39\n",
            "12/03/2021 20:46:32 - INFO - __main__ -   [Iter 126000] Loss 3.36  Val Loss: 7.55  Val Perplexity: 1902.63\n",
            "12/03/2021 20:46:55 - INFO - __main__ -   [Iter 128000] Loss 3.37  Val Loss: 7.62  Val Perplexity: 2028.69\n",
            "12/03/2021 20:47:18 - INFO - __main__ -   [Iter 130000] Loss 3.42  Val Loss: 7.65  Val Perplexity: 2091.72\n",
            "12/03/2021 20:47:41 - INFO - __main__ -   [Iter 132000] Loss 3.47  Val Loss: 7.64  Val Perplexity: 2083.51\n",
            "12/03/2021 20:48:04 - INFO - __main__ -   [Iter 134000] Loss 3.52  Val Loss: 7.65  Val Perplexity: 2093.13\n",
            "12/03/2021 20:48:27 - INFO - __main__ -   [Iter 136000] Loss 3.57  Val Loss: 7.68  Val Perplexity: 2157.25\n",
            "12/03/2021 20:48:50 - INFO - __main__ -   [Iter 138000] Loss 3.62  Val Loss: 7.67  Val Perplexity: 2144.12\n",
            "12/03/2021 20:49:13 - INFO - __main__ -   [Iter 140000] Loss 3.67  Val Loss: 7.68  Val Perplexity: 2156.52\n",
            "12/03/2021 20:49:36 - INFO - __main__ -   [Iter 142000] Loss 3.71  Val Loss: 7.68  Val Perplexity: 2172.47\n",
            "12/03/2021 20:49:59 - INFO - __main__ -   [Iter 144000] Loss 3.76  Val Loss: 7.66  Val Perplexity: 2123.17\n",
            "12/03/2021 20:50:22 - INFO - __main__ -   [Iter 146000] Loss 3.79  Val Loss: 7.68  Val Perplexity: 2169.90\n",
            "12/03/2021 20:50:45 - INFO - __main__ -   [Iter 148000] Loss 3.83  Val Loss: 7.71  Val Perplexity: 2228.98\n",
            "12/03/2021 20:51:08 - INFO - __main__ -   [Iter 150000] Loss 3.02  Val Loss: 7.68  Val Perplexity: 2169.86\n",
            "12/03/2021 20:51:31 - INFO - __main__ -   [Iter 152000] Loss 3.06  Val Loss: 7.76  Val Perplexity: 2350.92\n",
            "12/03/2021 20:51:54 - INFO - __main__ -   [Iter 154000] Loss 3.11  Val Loss: 7.80  Val Perplexity: 2435.69\n",
            "12/03/2021 20:52:17 - INFO - __main__ -   [Iter 156000] Loss 3.16  Val Loss: 7.82  Val Perplexity: 2488.41\n",
            "12/03/2021 20:52:41 - INFO - __main__ -   [Iter 158000] Loss 3.21  Val Loss: 7.82  Val Perplexity: 2502.32\n",
            "12/03/2021 20:53:04 - INFO - __main__ -   [Iter 160000] Loss 3.26  Val Loss: 7.84  Val Perplexity: 2528.13\n",
            "12/03/2021 20:53:27 - INFO - __main__ -   [Iter 162000] Loss 3.31  Val Loss: 7.86  Val Perplexity: 2585.71\n",
            "12/03/2021 20:53:49 - INFO - __main__ -   [Iter 164000] Loss 3.36  Val Loss: 7.85  Val Perplexity: 2567.49\n",
            "12/03/2021 20:54:13 - INFO - __main__ -   [Iter 166000] Loss 3.40  Val Loss: 7.86  Val Perplexity: 2595.46\n",
            "12/03/2021 20:54:36 - INFO - __main__ -   [Iter 168000] Loss 3.44  Val Loss: 7.87  Val Perplexity: 2608.64\n",
            "12/03/2021 20:54:59 - INFO - __main__ -   [Iter 170000] Loss 3.48  Val Loss: 7.85  Val Perplexity: 2565.97\n",
            "12/03/2021 20:55:22 - INFO - __main__ -   [Iter 172000] Loss 3.52  Val Loss: 7.84  Val Perplexity: 2546.69\n",
            "12/03/2021 20:55:45 - INFO - __main__ -   [Iter 174000] Loss 3.56  Val Loss: 7.82  Val Perplexity: 2493.82\n",
            "12/03/2021 20:56:01 - INFO - __main__ -   ***** Eval results *****\n",
            "12/03/2021 20:56:01 - INFO - __main__ -     eval_loss = 7.830698525505066\n",
            "12/03/2021 20:56:01 - INFO - __main__ -     eval_perplexity = 2516.686729437401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2HQpMw6MIAZ",
        "outputId": "03a69979-f9d7-4798-f101-dc16946eb844"
      },
      "source": [
        "!python run_lstm.py \\\n",
        "  --username \"wsj\" \\\n",
        "  --num_epochs 7 \\\n",
        "  --eval_every 2000 \\\n",
        "  --hidden_size 512 \\\n",
        "  --embedding_dim 300 \\\n",
        "  --lr 0.0004"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/My Drive/NLP/project/dataset.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  df = df[filter]\n",
            "[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 9000     /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 18000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 26000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Namespace(bos_token='<BOS>', dropout=0.2, embedding_dim=300, eos_token='<EOS>', eval_every=2000, hidden_size=512, length=50, lr=0.0004, n_gpu=1, n_layers=1, no_cuda=False, num_epochs=7, output_dir='outputs', seed=42, train_split=0.8, use_pretrained_embeddings=False, username='wsj')\n",
            "12/03/2021 20:56:33 - INFO - __main__ -   [Iter 2000] Loss 7.53  Val Loss: 7.20  Val Perplexity: 1336.73\n",
            "12/03/2021 20:56:55 - INFO - __main__ -   [Iter 4000] Loss 7.29  Val Loss: 7.03  Val Perplexity: 1124.46\n",
            "12/03/2021 20:57:17 - INFO - __main__ -   [Iter 6000] Loss 7.15  Val Loss: 6.98  Val Perplexity: 1074.12\n",
            "12/03/2021 20:57:39 - INFO - __main__ -   [Iter 8000] Loss 7.05  Val Loss: 6.79  Val Perplexity: 886.95\n",
            "12/03/2021 20:58:02 - INFO - __main__ -   [Iter 10000] Loss 6.97  Val Loss: 6.70  Val Perplexity: 816.15\n",
            "12/03/2021 20:58:24 - INFO - __main__ -   [Iter 12000] Loss 6.90  Val Loss: 6.69  Val Perplexity: 805.57\n",
            "12/03/2021 20:58:46 - INFO - __main__ -   [Iter 14000] Loss 6.85  Val Loss: 6.63  Val Perplexity: 758.70\n",
            "12/03/2021 20:59:08 - INFO - __main__ -   [Iter 16000] Loss 6.80  Val Loss: 6.58  Val Perplexity: 723.02\n",
            "12/03/2021 20:59:30 - INFO - __main__ -   [Iter 18000] Loss 6.75  Val Loss: 6.56  Val Perplexity: 709.58\n",
            "12/03/2021 20:59:53 - INFO - __main__ -   [Iter 20000] Loss 6.71  Val Loss: 6.53  Val Perplexity: 684.14\n",
            "12/03/2021 21:00:15 - INFO - __main__ -   [Iter 22000] Loss 6.68  Val Loss: 6.51  Val Perplexity: 669.41\n",
            "12/03/2021 21:00:37 - INFO - __main__ -   [Iter 24000] Loss 5.65  Val Loss: 6.52  Val Perplexity: 679.29\n",
            "12/03/2021 21:00:59 - INFO - __main__ -   [Iter 26000] Loss 5.64  Val Loss: 6.55  Val Perplexity: 701.47\n",
            "12/03/2021 21:01:21 - INFO - __main__ -   [Iter 28000] Loss 5.64  Val Loss: 6.57  Val Perplexity: 716.48\n",
            "12/03/2021 21:01:44 - INFO - __main__ -   [Iter 30000] Loss 5.64  Val Loss: 6.58  Val Perplexity: 718.59\n",
            "12/03/2021 21:02:06 - INFO - __main__ -   [Iter 32000] Loss 5.67  Val Loss: 6.59  Val Perplexity: 726.92\n",
            "12/03/2021 21:02:28 - INFO - __main__ -   [Iter 34000] Loss 5.68  Val Loss: 6.57  Val Perplexity: 713.91\n",
            "12/03/2021 21:02:50 - INFO - __main__ -   [Iter 36000] Loss 5.69  Val Loss: 6.55  Val Perplexity: 701.30\n",
            "12/03/2021 21:03:12 - INFO - __main__ -   [Iter 38000] Loss 5.70  Val Loss: 6.56  Val Perplexity: 703.93\n",
            "12/03/2021 21:03:34 - INFO - __main__ -   [Iter 40000] Loss 5.71  Val Loss: 6.54  Val Perplexity: 692.25\n",
            "12/03/2021 21:03:57 - INFO - __main__ -   [Iter 42000] Loss 5.72  Val Loss: 6.56  Val Perplexity: 707.39\n",
            "12/03/2021 21:04:19 - INFO - __main__ -   [Iter 44000] Loss 5.73  Val Loss: 6.54  Val Perplexity: 692.49\n",
            "12/03/2021 21:04:41 - INFO - __main__ -   [Iter 46000] Loss 5.73  Val Loss: 6.55  Val Perplexity: 699.99\n",
            "12/03/2021 21:05:03 - INFO - __main__ -   [Iter 48000] Loss 4.89  Val Loss: 6.59  Val Perplexity: 728.30\n",
            "12/03/2021 21:05:26 - INFO - __main__ -   [Iter 50000] Loss 4.87  Val Loss: 6.64  Val Perplexity: 763.48\n",
            "12/03/2021 21:05:48 - INFO - __main__ -   [Iter 52000] Loss 4.91  Val Loss: 6.65  Val Perplexity: 769.10\n",
            "12/03/2021 21:06:10 - INFO - __main__ -   [Iter 54000] Loss 4.94  Val Loss: 6.65  Val Perplexity: 771.66\n",
            "12/03/2021 21:06:32 - INFO - __main__ -   [Iter 56000] Loss 4.98  Val Loss: 6.66  Val Perplexity: 782.38\n",
            "12/03/2021 21:06:55 - INFO - __main__ -   [Iter 58000] Loss 5.01  Val Loss: 6.66  Val Perplexity: 780.18\n",
            "12/03/2021 21:07:17 - INFO - __main__ -   [Iter 60000] Loss 5.04  Val Loss: 6.67  Val Perplexity: 789.83\n",
            "12/03/2021 21:07:39 - INFO - __main__ -   [Iter 62000] Loss 5.08  Val Loss: 6.68  Val Perplexity: 799.88\n",
            "12/03/2021 21:08:01 - INFO - __main__ -   [Iter 64000] Loss 5.10  Val Loss: 6.66  Val Perplexity: 782.17\n",
            "12/03/2021 21:08:23 - INFO - __main__ -   [Iter 66000] Loss 5.12  Val Loss: 6.66  Val Perplexity: 783.66\n",
            "12/03/2021 21:08:46 - INFO - __main__ -   [Iter 68000] Loss 5.15  Val Loss: 6.67  Val Perplexity: 791.50\n",
            "12/03/2021 21:09:08 - INFO - __main__ -   [Iter 70000] Loss 5.17  Val Loss: 6.66  Val Perplexity: 782.80\n",
            "12/03/2021 21:09:30 - INFO - __main__ -   [Iter 72000] Loss 4.29  Val Loss: 6.75  Val Perplexity: 849.84\n",
            "12/03/2021 21:09:52 - INFO - __main__ -   [Iter 74000] Loss 4.31  Val Loss: 6.79  Val Perplexity: 886.91\n",
            "12/03/2021 21:10:14 - INFO - __main__ -   [Iter 76000] Loss 4.35  Val Loss: 6.79  Val Perplexity: 887.89\n",
            "12/03/2021 21:10:37 - INFO - __main__ -   [Iter 78000] Loss 4.40  Val Loss: 6.82  Val Perplexity: 919.74\n",
            "12/03/2021 21:10:59 - INFO - __main__ -   [Iter 80000] Loss 4.44  Val Loss: 6.82  Val Perplexity: 919.79\n",
            "12/03/2021 21:11:21 - INFO - __main__ -   [Iter 82000] Loss 4.48  Val Loss: 6.85  Val Perplexity: 944.55\n",
            "12/03/2021 21:11:43 - INFO - __main__ -   [Iter 84000] Loss 4.52  Val Loss: 6.84  Val Perplexity: 931.49\n",
            "12/03/2021 21:12:05 - INFO - __main__ -   [Iter 86000] Loss 4.56  Val Loss: 6.83  Val Perplexity: 929.58\n",
            "12/03/2021 21:12:28 - INFO - __main__ -   [Iter 88000] Loss 4.59  Val Loss: 6.83  Val Perplexity: 922.67\n",
            "12/03/2021 21:12:50 - INFO - __main__ -   [Iter 90000] Loss 4.62  Val Loss: 6.82  Val Perplexity: 919.70\n",
            "12/03/2021 21:13:12 - INFO - __main__ -   [Iter 92000] Loss 4.65  Val Loss: 6.83  Val Perplexity: 925.63\n",
            "12/03/2021 21:13:34 - INFO - __main__ -   [Iter 94000] Loss 4.68  Val Loss: 6.83  Val Perplexity: 924.33\n",
            "12/03/2021 21:13:56 - INFO - __main__ -   [Iter 96000] Loss 3.79  Val Loss: 6.91  Val Perplexity: 1000.39\n",
            "12/03/2021 21:14:19 - INFO - __main__ -   [Iter 98000] Loss 3.84  Val Loss: 6.93  Val Perplexity: 1019.44\n",
            "12/03/2021 21:14:41 - INFO - __main__ -   [Iter 100000] Loss 3.90  Val Loss: 6.96  Val Perplexity: 1050.88\n",
            "12/03/2021 21:15:03 - INFO - __main__ -   [Iter 102000] Loss 3.96  Val Loss: 6.98  Val Perplexity: 1073.18\n",
            "12/03/2021 21:15:25 - INFO - __main__ -   [Iter 104000] Loss 4.01  Val Loss: 6.97  Val Perplexity: 1069.49\n",
            "12/03/2021 21:15:47 - INFO - __main__ -   [Iter 106000] Loss 4.06  Val Loss: 6.99  Val Perplexity: 1081.61\n",
            "12/03/2021 21:16:10 - INFO - __main__ -   [Iter 108000] Loss 4.09  Val Loss: 7.01  Val Perplexity: 1102.40\n",
            "12/03/2021 21:16:32 - INFO - __main__ -   [Iter 110000] Loss 4.13  Val Loss: 6.98  Val Perplexity: 1077.73\n",
            "12/03/2021 21:16:54 - INFO - __main__ -   [Iter 112000] Loss 4.17  Val Loss: 6.99  Val Perplexity: 1085.57\n",
            "12/03/2021 21:17:16 - INFO - __main__ -   [Iter 114000] Loss 4.21  Val Loss: 6.97  Val Perplexity: 1065.53\n",
            "12/03/2021 21:17:38 - INFO - __main__ -   [Iter 116000] Loss 4.25  Val Loss: 7.00  Val Perplexity: 1095.48\n",
            "12/03/2021 21:18:01 - INFO - __main__ -   [Iter 118000] Loss 3.16  Val Loss: 6.99  Val Perplexity: 1087.64\n",
            "12/03/2021 21:18:23 - INFO - __main__ -   [Iter 120000] Loss 3.42  Val Loss: 7.06  Val Perplexity: 1168.32\n",
            "12/03/2021 21:18:45 - INFO - __main__ -   [Iter 122000] Loss 3.46  Val Loss: 7.10  Val Perplexity: 1210.11\n",
            "12/03/2021 21:19:07 - INFO - __main__ -   [Iter 124000] Loss 3.52  Val Loss: 7.15  Val Perplexity: 1268.02\n",
            "12/03/2021 21:19:29 - INFO - __main__ -   [Iter 126000] Loss 3.59  Val Loss: 7.15  Val Perplexity: 1274.18\n",
            "12/03/2021 21:19:52 - INFO - __main__ -   [Iter 128000] Loss 3.64  Val Loss: 7.14  Val Perplexity: 1264.83\n",
            "12/03/2021 21:20:14 - INFO - __main__ -   [Iter 130000] Loss 3.68  Val Loss: 7.15  Val Perplexity: 1275.88\n",
            "12/03/2021 21:20:36 - INFO - __main__ -   [Iter 132000] Loss 3.73  Val Loss: 7.16  Val Perplexity: 1291.25\n",
            "12/03/2021 21:20:58 - INFO - __main__ -   [Iter 134000] Loss 3.78  Val Loss: 7.16  Val Perplexity: 1288.95\n",
            "12/03/2021 21:21:21 - INFO - __main__ -   [Iter 136000] Loss 3.82  Val Loss: 7.17  Val Perplexity: 1293.76\n",
            "12/03/2021 21:21:43 - INFO - __main__ -   [Iter 138000] Loss 3.86  Val Loss: 7.16  Val Perplexity: 1288.11\n",
            "12/03/2021 21:22:05 - INFO - __main__ -   [Iter 140000] Loss 3.90  Val Loss: 7.15  Val Perplexity: 1267.95\n",
            "12/03/2021 21:22:28 - INFO - __main__ -   [Iter 142000] Loss 3.05  Val Loss: 7.18  Val Perplexity: 1314.92\n",
            "12/03/2021 21:22:50 - INFO - __main__ -   [Iter 144000] Loss 3.09  Val Loss: 7.24  Val Perplexity: 1397.93\n",
            "12/03/2021 21:23:12 - INFO - __main__ -   [Iter 146000] Loss 3.15  Val Loss: 7.28  Val Perplexity: 1450.54\n",
            "12/03/2021 21:23:34 - INFO - __main__ -   [Iter 148000] Loss 3.20  Val Loss: 7.31  Val Perplexity: 1496.38\n",
            "12/03/2021 21:23:57 - INFO - __main__ -   [Iter 150000] Loss 3.26  Val Loss: 7.34  Val Perplexity: 1547.04\n",
            "12/03/2021 21:24:19 - INFO - __main__ -   [Iter 152000] Loss 3.32  Val Loss: 7.33  Val Perplexity: 1531.51\n",
            "12/03/2021 21:24:41 - INFO - __main__ -   [Iter 154000] Loss 3.38  Val Loss: 7.32  Val Perplexity: 1515.29\n",
            "12/03/2021 21:25:03 - INFO - __main__ -   [Iter 156000] Loss 3.42  Val Loss: 7.32  Val Perplexity: 1504.86\n",
            "12/03/2021 21:25:26 - INFO - __main__ -   [Iter 158000] Loss 3.47  Val Loss: 7.33  Val Perplexity: 1532.87\n",
            "12/03/2021 21:25:48 - INFO - __main__ -   [Iter 160000] Loss 3.51  Val Loss: 7.32  Val Perplexity: 1516.26\n",
            "12/03/2021 21:26:10 - INFO - __main__ -   [Iter 162000] Loss 3.55  Val Loss: 7.31  Val Perplexity: 1488.02\n",
            "12/03/2021 21:26:32 - INFO - __main__ -   [Iter 164000] Loss 3.60  Val Loss: 7.32  Val Perplexity: 1508.66\n",
            "12/03/2021 21:26:49 - INFO - __main__ -   ***** Eval results *****\n",
            "12/03/2021 21:26:49 - INFO - __main__ -     eval_loss = 7.307927451962132\n",
            "12/03/2021 21:26:49 - INFO - __main__ -     eval_perplexity = 1492.081571657841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9fl6_I19kpQ"
      },
      "source": [
        "## Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l06lhdCq9EEP",
        "outputId": "a9614f97-26ac-4fc8-b94b-3fd6a0934870"
      },
      "source": [
        "!python run_lstm_generation.py \\\n",
        "  --username \"elonmusk\" \\\n",
        "  --num_sequences 10 \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --seed 52"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/03/2021 21:27:05 - INFO - __main__ -   Sample 0: Tesla software V10. 0 comes with karaoke\n",
            "12/03/2021 21:27:05 - INFO - __main__ -   Sample 1: \n",
            "12/03/2021 21:27:05 - INFO - __main__ -   Sample 2: Tesla Supercharger network now energized from Cape Canaveral to California, but the second derivative bodes on the droneship. Just need the future.\n",
            "12/03/2021 21:27:05 - INFO - __main__ -   Sample 3: Just leaving SpaceX Starship build site in Boca\n",
            "12/03/2021 21:27:05 - INFO - __main__ -   Sample 4: Will be live streaming the Gigafactory launch party tonight. Check this eve.\n",
            "12/03/2021 21:27:05 - INFO - __main__ -   Sample 5: Falcon Heavy goes vertical\n",
            "12/03/2021 21:27:05 - INFO - __main__ -   Sample 6: Falcon Heavy goes vertical\n",
            "12/03/2021 21:27:05 - INFO - __main__ -   Sample 7: At Tesla Giga Shanghai NSFW!!\n",
            "12/03/2021 21:27:05 - INFO - __main__ -   Sample 8: Tesla deliveries & AP hardware chart by @ lexfridman at MIT\n",
            "12/03/2021 21:27:05 - INFO - __main__ -   Sample 9: Just leaving SpaceX Starship build site in Boca\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHT935-I9Vmo",
        "outputId": "ab9f6d9c-b0e3-449e-97f9-2a8b869ad4e3"
      },
      "source": [
        "!python run_lstm_generation.py \\\n",
        "  --username \"karpathy\" \\\n",
        "  --num_sequences 10 \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --seed 52"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/03/2021 21:27:10 - INFO - __main__ -   Sample 0: Awesome : \" The Drill of Depth \" ( Portable Kinect 3D Camera ) from David Cox lab ( @ neurobongo )\n",
            "12/03/2021 21:27:10 - INFO - __main__ -   Sample 1: At last, Stanford presentation. Fun, will look at all. I like the same direction. \" 1\n",
            "12/03/2021 21:27:10 - INFO - __main__ -   Sample 2: This is a motherfucking website. the guy has a point\n",
            "12/03/2021 21:27:10 - INFO - __main__ -   Sample 3: I hate a new new trend about designs with ConvNetJS from a nice MLdata science blog : & video of your pet with Robots\n",
            "12/03/2021 21:27:10 - INFO - __main__ -   Sample 4: One of my favorite funny YouTube clips : \" Everythings Amazing & Nobodys Happy \" ( fun starts ~) 1\n",
            "12/03/2021 21:27:10 - INFO - __main__ -   Sample 5: Wow pretending to be blind is Really hard! 1\n",
            "12/03/2021 21:27:10 - INFO - __main__ -   Sample 6: I know that take 1\n",
            "12/03/2021 21:27:10 - INFO - __main__ -   Sample 7: # icra2013 robots batch two vine. co Andrej Karpathy' s post on Vine # icra2013 robots batch two\n",
            "12/03/2021 21:27:10 - INFO - __main__ -   Sample 8: New Facebook feed looks good idea but I can' t help but it' s not right.\n",
            "12/03/2021 21:27:10 - INFO - __main__ -   Sample 9: I' m witnessing the worst ( and it doesn' t work ( and ) is a good stuff. And it' s a thing!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F04BO-4i9XZ6",
        "outputId": "ba7947e2-836a-48b6-c264-afd2c7c57d13"
      },
      "source": [
        "!python run_lstm_generation.py \\\n",
        "  --username \"BarackObama\" \\\n",
        "  --num_sequences 10 \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --seed 52"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/03/2021 21:27:15 - INFO - __main__ -   Sample 0: President Obama : “ I ’ ll use the money we ’ re fighting to create the future that ’ s not going.”\n",
            "12/03/2021 21:27:15 - INFO - __main__ -   Sample 1: President Obama : \" We have to renew our military around the world in our commitment to fight back against all of us.”\n",
            "12/03/2021 21:27:15 - INFO - __main__ -   Sample 2: “ We believe we have a strong, middle - class opportunity for all that hard work and responsibility is rewarded.”— President Obama\n",
            "12/03/2021 21:27:15 - INFO - __main__ -   Sample 3: FACT : Obama' s plan to reduce the deficit by $ 4 trillion to $ 4 trillion in 10 years. # BuffettRule\n",
            "12/03/2021 21:27:15 - INFO - __main__ -   Sample 4: Have you heard?\n",
            "12/03/2021 21:27:15 - INFO - __main__ -   Sample 5: Read the latest op - ed from @ nytimes : \" We can bring the job with a balanced plan that would make it harder for our people and our future.\"\n",
            "12/03/2021 21:27:15 - INFO - __main__ -   Sample 6: President Obama : “ I am not going to cut carbon pollution power to the country. I still believe that change is not.”\n",
            "12/03/2021 21:27:15 - INFO - __main__ -   Sample 7: \" A hard day ’ s work deserves a fair day — that ’ s what this is what we should do — not change — that ’ s about jobs — that ’ s why we will be close.\" # DemandAction\n",
            "12/03/2021 21:27:15 - INFO - __main__ -   Sample 8: “ I am the voting with a balanced approach that women for $ 14, 500 in the states that ’ s in the United States.”\n",
            "12/03/2021 21:27:15 - INFO - __main__ -   Sample 9: \" I' m only here because the CleanWater we passed to talk about putting a balanced approach to deficit reduction.\" — President Obama\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEM8LQ_p9ZSX",
        "outputId": "d8e5686b-f062-4400-bec9-19b86a28121e"
      },
      "source": [
        "!python run_lstm_generation.py \\\n",
        "  --username \"cnn\" \\\n",
        "  --num_sequences 10 \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --seed 52"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/03/2021 21:27:20 - INFO - __main__ -   Sample 0: Opinion : An e - commerce is likely to be a budget, writes @ jasonrileywsj\n",
            "12/03/2021 21:27:20 - INFO - __main__ -   Sample 1: After years of a man, the attack, was the deaths of violence in the past four days of a attack on June 2012.\n",
            "12/03/2021 21:27:20 - INFO - __main__ -   Sample 2: How to put the rule of violence\n",
            "12/03/2021 21:27:20 - INFO - __main__ -   Sample 3: The U. S. has backed since the U. S. to five years ago. Will the new set of new rules?\n",
            "12/03/2021 21:27:20 - INFO - __main__ -   Sample 4: :' The talk of' has been for them.\n",
            "12/03/2021 21:27:20 - INFO - __main__ -   Sample 5: GM to Settle SEC America\n",
            "12/03/2021 21:27:20 - INFO - __main__ -   Sample 6: As the world, we' re make a comeback :\n",
            "12/03/2021 21:27:20 - INFO - __main__ -   Sample 7: For your neighborhood, being a slowing like a lot by \" no \" too much.\n",
            "12/03/2021 21:27:20 - INFO - __main__ -   Sample 8: Opinion : How to stop the ones of the NFL in the House tax bill\n",
            "12/03/2021 21:27:20 - INFO - __main__ -   Sample 9: A new leader FDA ’ s phone on the internet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9Par9ur9aez",
        "outputId": "ef036ee3-f4f7-4466-f782-1337b42589f4"
      },
      "source": [
        "!python run_lstm_generation.py \\\n",
        "  --username \"wsj\" \\\n",
        "  --num_sequences 10 \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --seed 52"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/03/2021 21:27:25 - INFO - __main__ -   Sample 0: Man kills wife, self in Mount death 2\n",
            "12/03/2021 21:27:25 - INFO - __main__ -   Sample 1: How did a # PoliticalTicker in a Twitter account of the @, and the the best and the sale of a # Rio2016 GIF\n",
            "12/03/2021 21:27:25 - INFO - __main__ -   Sample 2: Man admits killing son, mother' s' found dead after 3\n",
            "12/03/2021 21:27:25 - INFO - __main__ -   Sample 3: A school teacher, the man who helped her home with two weeks after decades accident.\n",
            "12/03/2021 21:27:25 - INFO - __main__ -   Sample 4: \" A - Rod is a missing of a couple that will be on a large via @ SarahHoyeCNN\n",
            "12/03/2021 21:27:25 - INFO - __main__ -   Sample 5: New York police have some ice resume for fall for # CNNdebate?\n",
            "12/03/2021 21:27:25 - INFO - __main__ -   Sample 6: The top 10 tech ‘ fails ’ of 2011.\n",
            "12/03/2021 21:27:25 - INFO - __main__ -   Sample 7: What' s on the Apple' s museum could be the next few hours before home before they may have been kidnapped on # CNNElections :\n",
            "12/03/2021 21:27:25 - INFO - __main__ -   Sample 8: , Alabama wins Search for emergency, study says.\n",
            "12/03/2021 21:27:25 - INFO - __main__ -   Sample 9: The man who made Officials is giving an update on the set of a gun operation at the White House. Watch live on @ CNN TV or\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "6_Si4yWoTT5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_lstm_metrics.py \\\n",
        "  --username \"elonmusk\" \\\n",
        "  --test_data_file \"data/elonmusk/test.txt\" \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --seed 52"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuWovbLzTXUB",
        "outputId": "2ba8bff8-7d86-4ec7-875e-841eaf53b502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "['Snowed in at Mt. Rushmore @GoParks', 'Ok u can have a little emerald', 'Climate change explained in comic book form by xkcd xkcd. com Earth Temperature Timeline', 'Paid respects to Masada earlier today. Live free or die.', \"That was intense Ten years ago today, we achieved our first successful launch — time flies when you're in a whole bunch of @SolarCity. com.\", 'Simulations as of 7am this morning', \"Don't do this\", 'Tesla wins top rating, followed, non - class would be much appreciated.', 'New model for evolution of intelligent life suggests probable emergence 2 billion years ago near galactic center', 'Attempting bring up of thruster pods 2 and 4', 'Painting the name on the droneship...', '78 % of people want to gentrify Mordor', \"Not easy coming up with a good cover story for an underground volcano lair, but I have it' s a name for a place to do an hour day in the morning.\", \"Just wrote a song called “ Don't doubt yer vibe ”\", 'Falcon has landed', 'This is why I think solar power will be the primary long term solution', 'Star Wars only had an $ 11M budget. Must have been in the galaxy of ridiculously low budgets.', \"Don't do this\", \"Got to regulate AIrobotics like we do food, drugs, drugs & work. Can't blow your :)\", 'Flight profile #FalconHeavy #SpaceX', 'Moving the Tesla announcement to Wednesday. Needs a few more days of refinement.', '…', 'Model S range curves in detail by version', 'Activists just lifted off & hit tether limits!', 'Sleeving SN2 dome in the high bay', 'Expect to reach preliminary conclusions regarding last flight by end of year. Will be cautious & retested.', 'Happy Easter! Follow the', 'Falcon Heavy goes vertical', 'Cybertruck unveil Thursday night', \"Aspirationally on a Mars. That' s why they knew …\", 'Dragon floating in the Pacific near California. Reentry scorch marks visible on the heat shield', 'Good morning', \"Glad you're ok @tylerthecreator\", \"Last night' s Tesla Powerwall and Powerpack unveiling\", 'Extreme wind shear over Cape Canaveral. Feels like a sledgehammer when supersonic in the vertical. Hoping for this could.', 'Deus in operation, it is not fair, but the plot is confusing & long detours.', 'Holding on solar array deployment until at least two thruster pods are active', 'Just finished an interview with Spaceflight Now. Some of your questions may be answered here :', 'Model S Signature series sold out as of today', 'Tesla Solarglass roof', 'Dragon floating in the Pacific near California. Reentry scorch marks visible on the heat shield', 'Socialism just set for SolarCity : 1. 5 million pounds of vac thrust!', \"Not easy coming up with a good cover story for an underground volcano lair, but I' m just a small off the - Model 3 and playing for @elonmusk @spacex. He' s a little swim.\", 'Saw The Dictator yesterday. Reminded me of Putin & the evidence, as it will be great, then finds in the rain.\" ( near injuries ). After about an update in the world.', 'Happy Home Planet Day!', 'Three Raptors on a Starship', 'The libertarian argument for a carbon tax', 'Mission of Tesla', 'Told the moon', 'Wish there was something we could do to help the people of Syria.']\n",
            "['Snowed in at Mt. Rushmore @GoParks', 'Ok u can have a little emerald', 'Climate change deniers claim \"scientists disagree\", same rebuttal used by tobacco industry about lung cancer for decades', 'Paid respects to Masada earlier today. Live free or die.', 'That was a total non sequitur btw', 'Simulations show launch ok with bad valve. Still, better to stop & fix. Recalling rockets after launch is not an option.', 'Don’t Doubt ur Vibe m.', 'Tesla should have a mega rave cave under the Berlin Gigafatory', 'New Tesla referral program just released', 'Attempting bring up of thruster pods 2 and 4', 'Painting the name on the droneship ...', '78% of people want to gentrify Mordor', 'Not having a big gas guzzler engine in front means there’s room for trunks in front & back, plus longer crumple zone for best safety of any midsize car It’s crazy how much stuff fits in a Model 3 twitter.comAlguireTimsta…', 'Just wanted to say thanks to everyone for testifying yesterday in Austin. Will hang around after press conf to thank people in person.', 'Falcon 9 lifting off with 1.3 mmmillion pounds of force', 'This is nothing. In a few years, that bot will move so fast you’ll need a strobe light to see it. Sweet dreams… we dead', 'Star Light, Star Bright', 'Don’t defy DeFi', 'Got to regulate AIrobotics like we do food, drugs, aircraft & cars. Public risks require public oversight. Getting rid of the FAA wdn’t make flying safer. They’re there for good reason.', 'Flight computer aborted rocket hold down firing. Anomaly addressed. Cycling systems to countdown', \"Moving at ~23 times speed of sound, circling Earth every ~90 minutes View of an orbital sunset from Dragon's cupola\", '… going to moon very soon', 'Model S options are out! Performance in red and black for me. I will deliver my car in JuneJuly.', 'Activists should be pushing for more moderates to advise President, not fewer. How could having only extremists advise him possibly be good?', 'Sleeving SN2 dome in the high bay', 'Expect to reach preliminary conclusions regarding last flight by end of week. Will brief key customers & FAA, then post on our website.', 'Happy 4th of July!!', 'Falcon Heavy side boosters can use most of the same airframe as Falcon 9, but center core needs to be buffed up a lot for transfer loads.', 'Cybertruck prototype in New York this weekend', 'Aspirationally acerbic alliteration -> Bullshit baffles brains', 'Dragon will travel from south of New Zealand to Florida in ~37 minutes', 'Good article on the interplanetary transport system on Gizmodo', 'Glad you’re ok @tylerthecreator', 'Last known state for rocket boost stage is 360 ms, Mach 1.1, 8.5 km altitude and roll rate close to zero (v important!)', 'Extreme wind shear over Cape Canaveral. Feels like a sledgehammer when supersonic in the vertical. Hoping it changes …', 'Deus ex machine learning', 'Holding on solar array deployment until at least two thruster pods are active', 'Just fired our Superdraco escape rocket engine at full thrust! Needed to carry astronauts on Dragon', 'Model S Signature series sold out as of today', 'Tesla Solar just relaunched. Lmk what you think …', 'Dragon 2 is designed to be able to land anywhere in the solar system. Red Dragon Mars mission is the first test flight.', 'Socialism vs capitalism is not even the right question. What really matters is avoiding monopolies that restrict people’s freedom.', 'Not that this really matters. All current rocket tech, including ours, sucks. Only when it becomes fully reusable, will it not suck.', \"Saw The Dictator yesterday. Reminded me of Putin's reelection. Seems like only yesterday since he was last in power.\", 'Happy Thanksgiving!', 'Three Raptors on a Starship', 'The Model S beta endurance car just passed 150,000 miles on a single battery pack!', 'Mission looks good. Started deploying the 10 Iridium satellites. Rocket is stable on the droneship.', 'Told you AI was dangerous!! Massive semen explosion after blaze hits bull artificial insemination facility, firefighters forced to dodge \"projectiles\"', 'Wish there was something we could do to help the people of Syria.']\n",
            "12/07/2021 19:44:12 - INFO - __main__ -   ***** Metrics results *****\n",
            "12/07/2021 19:44:12 - INFO - __main__ -       bertscore_f1 = 0.8824729323387146\n",
            "12/07/2021 19:44:12 - INFO - __main__ -       bertscore_precision = 0.8870217204093933\n",
            "12/07/2021 19:44:12 - INFO - __main__ -       bertscore_recall = 0.8784558176994324\n",
            "12/07/2021 19:44:12 - INFO - __main__ -       bleu_score = 0.7043814477212029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_lstm_metrics.py \\\n",
        "  --username \"karpathy\" \\\n",
        "  --test_data_file \"data/karpathy/test.txt\" \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --seed 52"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpZ3dY0kbMzf",
        "outputId": "c7db42d1-8ea2-4207-93a1-8c57ff0333b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[\"Up Google Glass what he has just made to do it up a printer. I' m too good in AI.\", 'RE: Boston Dynamics Spot video & with new Python: smooth by Google Reader Robots: The Internship direction, depressing!', \"I can' t be at lunch with each step... that wrote people has a new, 000 page. What do the very good problem\", 'A lecture of convex optimization a day keeps the confusion away', 'Yummy in an app for pretty: fun, activities detailed, author of my physics - life gone works \" research PR of 10 data: for GPU processing on GPU: D', 'Recurrent Net Dreams Up Fake Chinese Characters in Vector Format with TensorFlow the TensorFlow in the AWS Cloud', 'My CVPR 2012 highlights', '3D printing on nanoscales. 3D printing is becoming cooler every day. 1', \"Speech2Face: Impressive video from ICRA' s concept Robot Dances Gangnam Style this is awesome! And\", \"I' m too good at hacking together simple baselines that later compete with my fancy method. I wonder if this. I made it to work better. #bliss\", 'Congrats, @YouTube, about them, a virtual, iPad, TensorFlow, Inference 1', 'Awesome: \" The Drill of Depth \" ( Portable Kinect 3D Camera ) from David Cox lab ( @neurobongo )', 'Working hours: Get a Life. Research on relationship between hours worked & productivity [ Economist ] 1', \"Computer Vision Lenna' s ( amusing ) story\", 'Kickstarter has its own favorite data formats: simple files, pickles,. mat files,. json files, protobufs, protobufs, 1,... 1', 'A nice Google Glass teardown:', 'A great collection of the followers of Google Street View [ by TechCrunch ] 1', \"I' m trying to iron out some UX game issues before I advertise more widely, and now I' m a feeling that will be me to it and go out 1\", 'Google + opened flood gates. Invite time!:) 1', 'Wingsuit videos are getting increasingly elaborate. Published today: How do Magnets work? well done 1', 'Haha: Thieves break into Microsoft offices. Only steal iPads 4', 'Research on solving Bongard problems: somehow these seem closely related to some core aspect of intelligence', '\" The Eulerian Video Magnification project from MIT CSAIL is on NYT as video, but looks like it kinda works:)', 'is the chatter of the day. \" Is connectivity a human right?\" + NYT article', \"By the part of Google' s Grasshopper rocket in the _worst_ ( visual system ) via @YouTube\", 'Ideally this morning. Like!! Exciting 1', \"I' m late to the party but very nicedetailedpractical ( and long!) intro from @michael_nielsen to put up in lab and #NoHope 1\", 'A very good Authors @Google talk about Inception. So much more to it than you would think.', 'Sitting in bookstore in bookstore I\\' ve always enjoyed the subject to argue in images. Was what that it\\' s the part of a day \"', 'This is the question: \" Here\\' s what we get the thousands of the things.', \"Visited London' s National Gallery. Was if it' s a thing! 1\", 'Wednesday a new iPad game on Kaggle tempting in 3D environments, not sure how I feel about this', 'Programming a particle engine on my iPad in Codify:)', 'ICLR a new gas papers just gave a \" Paints size as \" Bitcoin \" over the way.\" That\\' s their \". A lot of great', 'Does Passing A Small Current Through Your Brain Really Make You Smarter? hmmm... curious. skeptical.', \"Wow: Steve Ballmer is a process computer that a nice article about it' s recent questionable happen to smaller!\", 'I\\' m in a one of denial my new iPhoto app \" on \" in our heads \" quite entertaining, they will do it 1', 'Hmm. I wrote a python script that accidentally processed itself into empty file. programming_ego --; #facepalm', 'yay the campus is back to a bicycle moving obstacle course!', 'My processing pipeline includes shell scripts, python scripts, some matlab code, c ++ code, cuda code, cuda code, cuda code, cuda 2', \"Former 3 minutes. Makes me to update the reason I' m not feeling this too well!: S\", 'My favorite part of the interview starts \" The Drill of Depth \" ( Portable Kinect 3D Camera ) from David Cox lab ( @neurobongo )', 'Why are there only 24 hours in a day??? I need more time!:((', 'hah, is a good idea, can rotate a full - \" at the \" - performance problem \"', \"I hope to see all the API. Not sure how to more likely and attention' s a rocket on wheels. Not sure more to be a nightmare about overfitting. 1\", 'I\\' m becoming a full - sentence on Coursera for progress in the morning. \" Is it will be live to start the world as a grandpa', 'As I\\' m reviewing: \" We got stuck \" out - trivial minute on Willow Garage and data new dropout idea that is coming to go to Berkeley', \"My friend is fast enough at Rubik' s cube to fit a vine. I think there will be a tear on my life to the cloud\", \"iOS7 is very good at Google. It' s not very well done, but I like the idea\", 'A nice Google Glass teardown:']\n",
            "['Up next in Nature: Dendrites not passive compute units! Ion channels implicated as basic computational units. 1', 'RE: Boston Dynamics Spot video & people\\'s response to seeing it get kicked. I wonder if \"robot cruelty\" will be a thing, or \"robot rights\"', \"I registered for Google IO and was happy and then just noticed it overlaps Perfectly with this year's CVPR. Not cool\", \"A tweet! Just because I didn't for a while :) leaving to Vancouver in 2 hours. A slice of pizza is in order\", 'Yummy data! Microsoft Academic Search was awesome API resource until it was taken down a few months ago Microsoft releases data for Academic Graph, 37GB of \"paper-paper citations, author-paper, paper-topic and so forth\"', \"Recurrent Model of Visual Attention in Torch Doesn't quite convey how simple REINFORCE update is, but nice post torch.ch Torch | Recurrent Model of Visual Attention Torch is a scientific computing framework for LuaJIT.\", 'My by-a-margin favorite educational YouTuber ( @cgpgrey ) is starting a new podcast \"Hello Internet\" subbed', '3D printing on nanoscales. 3D printing is becoming cooler every day. 1', 'Speech2Face: Learning the Face Behind a Voice With increasingly largeeffective library of neural net encoders of any X and decoders of any Y, any source of paired data X,Y can give X2Y nets. And opens the door to many X2Y2Z2W...2X', 'I wish tax forms and related legal documents were written in English. I had to stumble on a 2-sentence Yahoo answers post to get this one', 'Congrats to good friend @RichardSocher and his new and exciting Deep Learning startup! a company to watch closely.', 'Awesome Google Research blog post on scaling up robotics ai.', 'Working hours: Get a Life. Research on relationship between hours worked & productivity [Economist] 1', 'Computer vision in the browser: Real time semi dense point tracking in javascript', 'Kickstarter has the most interesting \"About us\" page I\\'ve seen so far (drag horizontally)', 'A terrible demo of using Voice Input to control new Xbox Voice recognition sucks as input, IMO. Companies, pls stop', 'A bit late to the party here, but \"State of AI Report 2019\" is a nice overall ambitious attempt at summarizing AI for \"research\" a bit too much RL and a bit too little vision. Interesting that vision is patented so much more than other areas (p85) stateof.ai State of AI Report 2021 The State of AI Report analyses the most interesting developments in AI. Read and download here.', 'I accidentally sipped remains of my coffee from yesterday instead of coffee from today. It was unpleasant. 2', 'Google wants to cover the Earth with balloons that beam internet to Earth. This is the Google I like', 'Wingsuit videos are immune to getting old 1', 'Haha: \"50 People On ‘The Most Intellectual Joke I Know\\'\" (via @thenilly )', 'Research on solving Bongard problems: somehow these seem closely related to some core aspect of intelligence', '\"The Future of Online Identity is Decentralized\" web identity is in a very bad place. Current good+easy blend is to not use \"Sign in with...\" but a (paid) password manager. But some dedicated service has to \"factor it out\". +HN', 'is the chatter of the day. \"Is connectivity a human right?\" +NYT article', \"By the beard of Zeus! Anchorman 2 was announced today! I don't know how to put this but this is kind of a big deal.\", 'Ideally never absorb information without predicting it first. Then you can update both 1) your knowledge but also 2) your generative model.', 'I updated the yesterday. Now with even more conferences for even more headaches! Feedback welcome', 'A critique of pure learning and what ANNs can learn from animal brains \"a large component of an animal’s behavioral repertoire is not the result of clever learning algorithms—supervised or unsupervised—but of behavior programs already present at birth.\"', 'Sitting in bookstore in moment of nostalgia reading one of my favorites: Mechanics by Landau&Lifshitz. I remember taking this 5 years ago :(', 'This is from 2 days ago, but Curiosity has now been on Mars for 1 year. Some reflectionscelebration from NASA:', 'Visited Apple for the first time. Spotted Jony at lunch. #visitsuccess Now I know which Apple Watch band he uses and must get the same', 'Wednesday is my favorite day at work- 8 hour block of uninterrupted hacking time and no other scheduled bs.', 'Programming Languages homework finished. Lambda calculus and many many many brackets... #exhausted 1', 'ICLR papers are now up . This year have to use CMT to seesubmit comments', 'Does Passing A Small Current Through Your Brain Really Make You Smarter? hmmm... curious. skeptical.', 'Wow: Steve Ballmer (Microsoft CEO) to resign within a year. Stock up 7% right after announcement', \"I'm a bit of a noob at photography, but I've always enjoyed the subject and dabbled with it a bit in...\", 'Hmm. I became followed by a person with 0 followers, 0 tweets and 1 followee (me). Stalker!!! Lol', 'yay has reached 1,000 registered users! Growing few dozen a day.', \"My friend is fast enough at Rubik's cube to fit into a vine :) vine.co Andrej Karpathy's post on Vine My friend is fast enough at Rubik's cube to fit into a vine :) 2\", \"Former Google Reader Product Manager on why Google Reader was shut down Spoiler: yes, it's Google+. Ohhhhhhasfdasgfd\", 'My dad emailed me a link to a funny video of a cat. I think he just discovered YouTube. 1', 'Why Twitter is obsolete | Social Media (via @bradacker22 ) -- some good points. agree i think', 'hah, OH from friend: \"papers are often written in a way to hide embarrassingsloppy details and the fact that the ideas are very simple\"', 'I found a code base that goes against everything I believe in and stand for as a person. It pains to think that some CPU had to execute that', \"I reduced the price of one of my iOS apps from $1 to free, went from 200 downloadsmonth to 3000. Seems like people really can't afford a $1\", 'As far as I can tell my convnet predicts \"Erotica\" for woman\\'s face sideways. Man face doesn\\'t do it. Having too much fun with this', 'My top Diablo 3 heroes are called Sigmoid, ReLU and tanh. Now creating Maxout crusader. Maybe one day someone will get it. 5', \"iOS7 has early support for multipath TCP spec. (use of several conns at same time) This tech can't come soon enough\", 'A good essay from Aaron Swartz on productivity. I can relate a lot to what he says and need to improve here.']\n",
            "12/07/2021 19:46:40 - INFO - __main__ -   ***** Metrics results *****\n",
            "12/07/2021 19:46:40 - INFO - __main__ -       bertscore_f1 = 0.840485692024231\n",
            "12/07/2021 19:46:40 - INFO - __main__ -       bertscore_precision = 0.8406060934066772\n",
            "12/07/2021 19:46:40 - INFO - __main__ -       bertscore_recall = 0.8406685590744019\n",
            "12/07/2021 19:46:40 - INFO - __main__ -       bleu_score = 0.530199082435945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_lstm_metrics.py \\\n",
        "  --username \"BarackObama\" \\\n",
        "  --test_data_file \"data/BarackObama/test.txt\" \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --seed 52"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qN4szULbTYN",
        "outputId": "8d86d02d-8266-4879-d3ed-78de3d4628b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "['\" Even if we just four days to go —it\\'s time for a change that is all about.\" —President Obama #ABetterBargain', '\" You know the should be able to afford.\" —President Obama #OpportunityForAll', 'Ready for summer?', 'Eric has a story that you need to hear:', \"Bonnie' s still got a day to commit to vote:\", 'Bahamian, on: @OFA is giving away. Read more: #hc09', 'In the weekly address, President Obama signed the payroll tax cut for small businesses and our economy:', '\" All of the sacrifice you make your voice heard.\" —President Obama #ABetterBargain', 'Our immigration system is broken. Tell the House of Representatives: #ActOnReform.', '\" This is not the American people. It\\' s an economic imperative.\" —President Obama #RaiseTheWage #OpportunityForAll', 'Help make sure folks have the information they need to get covered in 2014: #LastCall2014', 'Today is the last day to enroll is covered. Help get out the vote this weekend:', 'Enjoy in America? Have the first time.', '\" Few - year is one of the best place to do business.\" —President Obama #ImmigrationAction', \"Welcoming the nation' s back on the same - sex policies that made in the USA —see their country:\", 'The President is counting on young people this November: #Gen44', 'Health insurance could be more affordable than you think:', 'Watch live: President Obama speaks in Nevada at the National Convention of the Veterans of Foreign Wars.', 'WATCH: President Obama is speaking at the Consumer Financial Protection Bureau.', 'WATCH: President Obama is speaking at the dedication ceremony of the National September 11 Memorial and Museum.', \"The President is in Virginia, speaking at Democratic Democratic National Convention. of the team's honor live tweets. Watch:\", \"“ Every American family is not a luxury anymore —it's about giving people's lives.”\", 'President Obama: \" I will work with anybody from on the ground and the rest of the world.\" #51volunteers', 'FACT: President Obama has signed 18 tax cuts to support small business growth. #progress', '\" The U. S. manufacturing production grew at its fastest pace since the first sitting president, and it is about.\" —President Obama', 'Michelle Obama on the last Dinner with Barack:', \".@OFA_PA @SpeakerBoehner's energy plan are working American jobs:\", 'Support the campaign from the White House:', \"As of the, we're a nation of innovation greater than $ 9. Follow the voting for the Obama - state trip:\", \"Good news: America' s taxes will get more than 1. 5 million Americans will cut their taxes.\", '\" These cuts are not smart. They\\'re not smart. They\\'re a self - inflicted wound that doesn\\' t have to happen.\" #JobsOverCuts', 'In Des Moines, IA on American clean energy in American innovation. Listen live at', \"President Obama: “ I think I need you to fight for a higher minimum wage because you can't just policy for a few.”\", 'Right now @OFA is looking for this year. See how these stories have work now:', '\" In a 21st century economy, the single best to this nation\\' s not as a country, and when we have a real impact on a solid foundation.\" —President Obama', '\" Sergeant of the demands the law is working hard to work better than men and women in uniform.\"', 'Kathy Republican reps on Twitter: @TheDemocrats ( OH - 07 ), @repbobgibbs ( OH - 07 ), @stevelatourette ( GA - 11 ), @heroism ( OH - 07 ).', '\" I want to make sure that everybody has a chance to give up to those who they love.\" —President Obama', \"President Obama: “ I don't believe that firing teachers or kicking students off financial aid will grow the economy.”—President Obama\", 'Happening now: The President delivers a statement on the latest developments in Iraq.', 'An average of four —be a part of this:', 'Get ready for the White House Summit on #WorkingFamilies, coming up on Monday:', 'Take a few minutes to write a letter to the editor highlighting this fall:', '\" We are all in the United States of America.\" —President Obama #SOTU', 'Made in the USA and all purchases go toward re - electing the President —and you could win a free trip:', 'Americans who are covered by the end of this: #LastCall2014', \"FACT: Romney would make college tax credit could cost $ 100, 000 a year with a woman's future. #DontDoubleMyRate\", '\" America is the last thing to do business. But the House is that hard work in the country.\" #GottaVote', 'Closing is real. Support @OFA and @OFA to help keep women be free and safe.', 'Expanding the news: Our economy is growing, and the economy are growing, and add your name. #Forward2012']\n",
            "['\"Even before taking office, I made clear that Iran would not be allowed to acquire a nuclear weapon on my watch.\" —President Obama #IranDeal', '\"You guys give me confidence. You guys give me hope. I really need all of you to get out and vote on Nov 2.\"', 'Ready for spring.', 'Eric has a story that you need to hear:', \"Bonnie's 23-year-old daughter was diagnosed with cancer. She wrote a letter everyone needs to read: #ACA\", 'Bahamian families and communities face a long recovery from Hurricane Dorian. And Americans are reaching out to help. Brittany Garvin is helping people reunite and evacuate.', \"In Indiana on the 40th anniv. of Dr. King's assassination. Asking everyone to continue his lifelong pursuit of social & economic justice.\", '\"All of our men and women in uniform around the world must know that they have our respect, our gratitude, and our full support.\" #SOTU', \"Our take: he's right. No major differences between Tea Party agenda and GOP candidates' policies.\", '\"This will be a year of action.\" —President Obama', 'Help organizers from across the country get the training needed to take their skills to the next level:', \"Today at p.m. ET: Don't miss President Obama's announcement on #climate change.\", 'Enjoy the holiday season with the ones you love. Michelle and I wish you a very Merry Christmas!', '\"Few things can have as negative an impact on our economy as climate change.\" —President Obama #ActOnClimate', \"Welcoming the nation's students back to school—watch today at noon ET:\", 'The final march for reform has begun. We need you to talk to your neighbors and help spread the facts on health reform:', 'Health care reform took generations of organizing. Say you were a part of this: (ht @OFA ) #8Million', 'Watch a livestream of the second inauguration here starting at 1am ET:', 'WATCH: President Obama discusses #CollegeOpportunity with students from across the country.', \"WATCH: The Obama administration supports a ban on conversion therapy to protect America's youth.\", 'The March 1st deadline is approaching. #GetCovered today:', '“Every time you fill up at the pump, they’re making money. They’re doing just fine.”—POTUS on ending Big Oil subsidies:', 'President Obama: \"Today, our businesses have created over 5 million new jobs. The American auto industry is back on top.\"', \"FACT: The Affordable Care Act allows young adults to stay on their parents' insurance until they are 26 years old.\", '\"The United States of America is the most powerful nation on Earth. Period.\" —President Obama #SOTU', 'Michelle and I send our condolences to the people of New Zealand. We grieve with you and the Muslim community. All of us must stand against hatred in all its forms.', '.@OFA_PA volunteers are building this campaign in the rain—reminding folks to vote in tomorrow’s primary:', 'Support the campaign from your front lawn with our 2012 yard signs:', 'As the June unemployment numbers are released, it is clear we are headed in the right direction, but we are not headed there fast enough.', 'Good news: The economy added 216,000 private sector jobs in May. #ActOnJobs', '\"These cuts are not smart. They will hurt our economy and cost us jobs—and Congress can turn them off at any time.\"', 'In Cedar Rapids, IA at Coe College for the MySpace MTV Presidential Dialogue. It will stream live at pm ET', 'President Obama: \"Over those 100 days or so, more than 100 times as many Americans have fallen victim to gun violence.\" #DemandAction', 'Right now @OFA is looking for new members for the team that will make 2014 a year to remember. Are you in?', '\"In no other nation on Earth could my story even be possible.\"', '\"Sergeant First Class Cory Remsburg never gives up, and he does not quit.\" —President Obama #SOTU', 'Kathy recalls #Nov4 2008: \"People danced; people sang. I had a feeling that the country had somehow changed in one evening.\"', '\"I promise you: You have a president who will take action to support working families.\" —President Obama #FamiliesSucceed', 'President Obama: \"Hello Colorado! Are you fired up? Are you ready to go?\" #AmericaForward', 'Happening now: President Obama is holding a press conference. Tune in.', 'An inside look at a GOP super PAC\\'s plan to \"do exactly what John McCain would not let us do\" in 2008:', 'Get a close look inside the first-ever @OFA Organizing Director Summit:', 'Take a look at what editorial boards across the country think of the Senate refusing to do its job: #DoYourJob', '\"We cannot ignore the problems that we have, but we can\\'t stop running the race.\" —President Obama', 'Made in the USA and all purchases go toward re-electing the President—take a look around the #Obama2012 store:', 'Americans want progress. This is about making it happen. Watch:', \"FACT: Romney's plan repeals Obamacare, won't protect families from insurance company abuses, and leaves 50 million more Americans uninsured.\", '\"America would have gone backwards. That\\'s not what we do. We move forward.\" —President Obama', \"Closing background check loopholes will save lives—and it's time for Congress to act. #DemandAction,\", \"Expanding #CollegeOpportunity is vital to America's success in a global economy:\"]\n",
            "12/07/2021 19:48:29 - INFO - __main__ -   ***** Metrics results *****\n",
            "12/07/2021 19:48:29 - INFO - __main__ -       bertscore_f1 = 0.8562716841697693\n",
            "12/07/2021 19:48:29 - INFO - __main__ -       bertscore_precision = 0.8540883660316467\n",
            "12/07/2021 19:48:29 - INFO - __main__ -       bertscore_recall = 0.8587515950202942\n",
            "12/07/2021 19:48:29 - INFO - __main__ -       bleu_score = 0.5282869244638766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_lstm_metrics.py \\\n",
        "  --username \"wsj\" \\\n",
        "  --test_data_file \"data/cnn/test.txt\" \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --seed 52"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qStGxYya4d2",
        "outputId": "79838b25-0382-47f2-e966-987665579b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "['on the #Sandy: 71 % of the U. S. Navy 2007 ; how it went down. Live coverage: #WorldCup', 'Wisconsin School of Business is \" not the first major currency to a budget deal with this year:', 'U. S. and Germany agree on new technology for breaking 1', 'U. S. Navy calls for first time since 2006.', \"RNC, a recent share sale at Uber, but with no skills and don't make @JasonGay\", \"Twitter's profit rises on Tuesday night with North Korea\", \"President Obama, speaking at a conference conference in, says it doesn't have to be a problem\", \"The U. S. to hold a $ 2. 55 billion deficit - backed company, plus 4 more stories of today' s top stories:\", \"D. C. S. was found guilty of certain stock market's commitment to fill the domestic market\", 'A New Jersey governor wants to raise a budget after the North Korea crisis, one suspected of missing out', 'CNN is in talks with its home with North Korea', 'Poll: No more than 1, 700 on Trump in New York and 2013, by one man has been part of the end.', \"Police: according - design isn't always any 2. 7 % this year. What' s next?\", ': How @WSJ reporters in your phone for home loans. What you can do now:', 'What are we should be the next Fed? \" I can\\'t imagine with the economy.', \"Sheriff' s Day says it can' t keep it to pay enough for more than $ 100 million\", 'Astronomers for years for the first time - ever policies', \", the U. S.’ s ‘,’ ’, the country's economic expansion was a lot like of an event\", \"CNN' s latest bitcoin futures is a new set for the of his daughter's office\", 'Employees are trying to revive the first office - building ): office inspired by some college grads:', \"What' s it like to be healthier: How the American workplace got the easier home - line?\", \"New York City steps up security for Sunday's gay pride parade\", \"This week, the lowest See how Clinton's budget has been in the U. S. Open men' s final:\", 'Florida Posts Loss Amid potential drugs', \"Smith & T' s new world - Assad Africa has long been by the side of the highest - largest ever - past\", 'BREAKING: plans to retire at least 100 people after falling of oil - production forces.', \"Women' s earnings rose in nearly 80 % since July 2009.\", \"Ex - Catholic Trump adviser said he would leave the Paris climate accord hasn't run for president\", '\" Sometimes it \" to the TV -- again to take a \" day as the next\\' s Fed.\"', 'AT & T to acquire Leap Wireless for $ 1. 4 billion in revenue fell on its first - ever - 88 - health - credit loans.', 'Mayor @WSJ: No. 2 million vehicles in the U. S. are', 'National Facebook security at present have been first for the biggest year to Congress', 'Reid:', 'UK:, who came ahead of Wall Street Journal', 'Report: and win takes another K -.’ problem in India', \"From to: Ben Carson was one of the first year in China after #Sandy? Follow @for tweets from today' s live blog:\", 'Texas judge down an abortion of, in an ancient streets', \"Knox: How the numbers of hotel renewed? He' s a With,' I' d be able to be good\", 'N. K. Cuomo 2', 'Rubin to Leave Washington Post 1', 'Nearly - 1, Texas church to use some residents and other major major oil production —into the country', 'for the World: \" It\\' s a lot for, like, is like a to #SuperBowl ads.', 'Second -, in 2', 'Canadian Cuts passes on Banks', 'Democrat: What is the new way to be Wi - Fi to target?', \"Here' s a look at the front page of today' s Wall Street Journal\", \"The U. S. says North Korea is ‘ a lot like to be've\", 'Sotomayor: the maternal mortality rate but not just for sale', 'The Dow Jones Industrial Average will continue to U. S. since 2004 and Google, its $ 1. 9 billion attacks on a key financial results', 'Is Arrested in Serbia']\n",
            "[\"Husband wants answers after wife's death sparks abortion debate in Ireland:\", 'Wisconsin Senate bypasses Democrats, OKs union limits.', 'U.S. Embassy in Kabul attacked.', 'U.S. drone shot down in eastern Iran, state media reports, citing military source.', \"RNC chairman condemns 'Magic Negro' song 1\", 'Twitter has restored a feature that allows users to \"block\" unwanted followers. money.', 'President Trump: \"Amazon is gonna have to pay much more money to the Post Office. There\\'s no doubt about that\"', 'The Defense Department has confirmed that leaked photos and video of \"unidentified aerial phenomena\" taken in 2019 are indeed legitimate images of unexplained objects', 'D.C. school system fires 241 teachers.', 'A man was killed by a crocodile nicknamed \"Michael Jackson.\" Here\\'s what police say appears to have happened:', 'CNN wants YOUR input to choose the most intriguing people of 2012:', 'Poll: Clinton and Trump neck-and-neck in Iowa', 'Police: Spears has minor accident in Mercedes', 'Transgender teen: \"My death needs to mean something.\" #LeelahAlcorn', 'What do you want to know about pop star Britney Spears’ fight to take back her life? Watch CNN Special Report: Toxic – Britney Spears’ Battle For Freedom to find out all about it. Tonight at 8 p.m. ET', \"Sheriff's deputies in Los Angeles handcuffed rapper Wyclef Jean after mistaking him for a robbery suspect\", 'Astronomers have discovered auroras on a brown dwarf 20 light-years away.', 'Witness in France says truck driver appeared to accelerate as he hit bodies', 'CNN\\'s Chief Medical Correspondent Dr. Sanjay Gupta fulfilled a lifelong dream by hosting \"Jeopardy!\" He is one of several guest hosts for the show.', 'Employees sacked over Ford art on tied-up women.', \"What's hiding in your food? @MorganSpurlock uncovers the things you probably shouldn't be eating on #InsideManCNN\", \"New York state officials are attempting to have a federal court throw out President Trump's lawsuit over the possible release of his tax returns to Congress, according to a new court filing\", 'This is @Bourdain \\'s favorite \"vegetable.\" Is it yours? Explore the flavors of Madagascar on #PartsUnknown tonight. vine.co CNN\\'s post on Vine This is Anthony Bourdain\\'s favorite \"vegetable.\" Is it yours? Explore the flavors of Madagascar on #PartsUnknown.', 'Florida mother shoots and kills infant son in murder-suicide attempt, police say:', 'Smith & Wesson shares hit an all-time high Monday', 'BREAKING NEWS: The Alabama Crimson Tide caps undefeated season with 37-21 win over Texas Longhorns in BCS title game.', 'Women\\'s suffragist Susan B. Anthony was never able to vote, so people are leaving \"I voted\" stickers on her grave', 'Ex-Catholic priest in photo scandal marries 2', '\"Sometimes we\\'re treated like mushrooms, we\\'re kept in the dark\": Rep. Garamendi says Niger briefing lacked details', 'AT&T to activate faster 4G network:', 'Mayor cleared in drug raid that left dogs dead', 'National guardsman reunited with dog days after tornado destroys town.', 'Reid: \"Watching white nationalists celebrate while innocent Americans cry tears of fear does not feel like America\"', 'UK: China executes British citizen.', 'Report: Fugitive suspected in Jakarta blasts 2', \"From CNN's Matthew Chance: Clashes outside the hotel. #Rixos4 hunkered down. #Libya @mchancecnn\", 'Texas Senator Ted Cruz pheasant hunts, bashes Obamacare in Iowa', \"Knox: 'I'm afraid to go back' to Italy. @ChrisCuomo 's wide-ranging intv wAmanda Knox; 10p ET Tues on CNN.\", 'N.K. has made nuclear progress, experts say', \"Rubin 'Hurricane' Carter still fighting long after boxing days pass.\", \"Nearly half of Florida's counties have agreed to provide Spanish-language assistance and materials to voters after a years-long legal battle\", 'Firefighter arrives to find own house in flames.', 'Second storm snarls traffic in Argentina: 9', 'Canadian skier arrested, accused of stealing car at Winter Olympics', \"Democrat: 'Ask Tiger, not me.'\", \"Here's how to get all your holiday shopping done in one day #BlackFriday\", 'The space shuttle Enterprise is flying over New York City right now - watch it live on @CNN TV or', \"Sotomayor: 'Law is not legal theory' 2\", \"The changing face of America's youth.\", 'Logic rules drug murders, trafficker says 2']\n",
            "12/07/2021 19:48:45 - INFO - __main__ -   ***** Metrics results *****\n",
            "12/07/2021 19:48:45 - INFO - __main__ -       bertscore_f1 = 0.8307070136070251\n",
            "12/07/2021 19:48:45 - INFO - __main__ -       bertscore_precision = 0.8290166258811951\n",
            "12/07/2021 19:48:45 - INFO - __main__ -       bertscore_recall = 0.8329724073410034\n",
            "12/07/2021 19:48:45 - INFO - __main__ -       bleu_score = 0.6108739147396758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_lstm_metrics.py \\\n",
        "  --username \"cnn\" \\\n",
        "  --test_data_file \"data/wsj/test.txt\" \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --seed 52"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXaSUv45bbcu",
        "outputId": "55d5dc25-8abe-4dee-f112-835d4a9bcb9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "['It\\'s not to be the US government money for a few weeks \" - @WolfBlitzer? @DonLemonCNN on CNN TV now.', \"India's Alabama: The ship that saved her that are...\", \"Take a tour of the' death of a symbol of life. ##PopeInNYC\", 'T. a. T. u., bail', 'REI\\'s oldest president: As questions about Donald Trump\\' s health care\\' s \" \" ( from @CNNMoney ):', 'Time to turn back to the NFL and sea by @SarahHoyeCNN', 'From a to a 17 - year with @BillWeirCNN and @CNNiReport:', 'In the newest jail, January 1, 800 or seven their lives on the Haiti.', \"Netflix' s son' s intriguing people.\", \"Opinion: Why I' ll Have Another?\", \"Obama: U. S.' will end' on rise, Donald Trump\", 'Breaking: CNN projects Donald Trump and Clinton in its GOP race, Colorado #Mandela. Details:', \"A @andersoncooper teacher's lead on @CNN TV at the White House. #CNNDebate\", 'The man who made shot at the moon.', 'All together now: \" I think I\\' m sorry \" at home:', 'General for Wall Street has resignation', \"Trump:' The Internet is happening is' 5\", ', former royal watch about Jackson doctor.', \"Goldman' s father gets new sex allegations\", 'More states reported in Brazil flooding.', ', the Tea Party Express first at Dallas victims, ChrisCuomo says.', 'During teen with two - year - old girl who was shot and killed him in connection with the entire #Ebola virus last night.', 'Florida man swallowed by sinkhole after getting arrest', 'The two years of the Afghan jail, social media reaction and more.', 'Open tornado outbreak linked to terror plot.', 'Rockets fall on Christmas emergency.', 'US Airways will be after Donald Trump -- and more than 4', 'As the polls close in the US U. S. #Syria?', 'Law may be as 000 as one time amid allegations of Congress.', \"BP' s adoption! It' s a job?\", 'The #ISIS video of tornado.', 'Jessica official charged: Moon Haiti children.', 'Stop children on rise after shooting.', ': Why Obama is pushing a country.', 'Is this a job? woman us back to the: via @CNNbelief', '7 die in Iraq near Iran blast', 'The \" should have the world \" - @CNNOpinion column by @PoliticalTicker:', 'Opinion: Germany hundreds of passengers likely to watch for at least 1: news. blogs.', ', former royal California plane crash.', \"Want to make your body? Go from you. We't need to know about the debate.\", 'Three shot in Phoenix office building:', 'Trump campaign CEO after Trump\\' s budget plan: \" We know it to watch out our future who\\' s greatest.\" @PiersMorgan on @AC360:', \"Opinion: Why we're in 5 things ( via @PoliticalTicker )\", 'Consumer Reports star, now linked with a record - setting reported.', \"GM' s February CEO to act.\", 'Ohio governor delays show of war crimes suspect 2', 'Federal John should be allowed to host your life of some:', 'Prime Minister 18 - year - old Colorado, who reported dead or from Afghanistan', 'Facing pays $ 1. 6 million in West, rain to close sex allegations', 'When this record GOP have gone too early to get it? See how this airline pay is more:']\n",
            "['It’s rocket science: North Korea lifts the hood on its newest missile', 'India’s Supreme Court is set to decide a closely watched case in a decadeslong dispute between Hindu and Muslim groups over control of an especially controversial religious site in northern India', 'Take an early look at the front page of The Wall Street Journal', 'T.a.T.u., a Russian pop duo with a lesbian image, is set to play Sochi Olympics opening ceremony.', 'REI’s new headquarters blur the boundaries between office and nature', 'Time for a rethink on Chinese property stocks — Heard on the Street', 'From @WSJopinion : “These freshmen give me faith that the post-#MeToo world might be a safer one.” Students reflect on the #MeToo era and its effect on college campuses.', 'In these world championships, competitors go for the gold in welding, baking, hairdressing and bricklaying', \"Netflix's Q2 earnings plummeted 91% as the company took in higher subscription costs. $NFLX\", 'Opinion: Air-traffic reform would reduce federal employees by more than 30,000 and federal spending by billions', \"Obama watched Mubarak's speech on Air Force One, then huddled with his national-security team\", 'Breaking: Bubba Watson wins the Masters, beating Louis Oosthuizen on the second hole of a playoff.', \"A company in Tokyo is using the 'Rocky' theme song to inspire Japanese workers to leave the office\", \"The NFL coaches best at ushering their teams into the future? They're the oldest ones\", 'All about the dark arts of cellphone signal-strength bars: \"It\\'s just a rough graphical presentation.\"', 'General Motors CEO Mary Barra finally reveals the whereabouts of the GM jetpacks', 'Trump drafted letter on why he wanted Comey out', 'Chesapeake Energy shares spiked after announcing CEO Aubrey K. McClendon will step down in April.', 'Goldman Sachs is considering shutting down its dark pool trading operation known as Sigma X.', 'More than 500 nuclear tests have been conducted above ground, but none since 1980', 'Centrist Democratic Sen. Joe Manchin of West Virginia stepped up his campaign to cut the price tag of Democrats’ $3.5 trillion healthcare, education and climate legislation, calling for a “strategic pause” in the effort', 'During World War I, a pigeon named Cher Ami delivered a message that saved nearly 200 U.S. soldiers despite losing a limb to enemy fire. Now members of his breed sell for big bucks.', 'Florida hospitals to settle Medicare-fraud allegations tied to unnecessary ambulance rides:', 'The FTC has ordered broadband providers to file detailed special reports on their data-handling and privacy practices within 45 days', 'Open surgeries did not see a sustained increase after the FDA warned of the risks of using power morcellators in hysterectomy operations, a study found', 'Rockets were fired from the Gaza Strip in what appeared to be an attack targeting a memorial ceremony for a slain Israeli soldier', 'US Airways to Cut Jobs, Raise Fees', 'As U.S. mulls moving embassy to Jerusalem, Palestinians feel helpless', 'Law schools are seeing the first significant uptick in applications in years. One of the reasons? Politics', 'BP\\'s \"top kill\" procedure has failed to stem the flow of oil into the Gulf; next step will take 4-7 days', 'The website that broke the story of the racist photo that is imperiling Virginia Democratic Gov. Ralph Northam is a pro-Trump outfit backed by Republican operatives', 'Jessica Alba’s Honest Co. has struggled to achieve sustainable growth after product woes', 'Stop counting calories. It’s the clock that counts.', 'Yum China is testing new technologies and menus in an effort to be more than finger lickin’ good', 'Is Twitter really worth $10 billion?', '7 myths (and truths) about olive oil:', 'The Domino’s tracking app delivers pizza to all, disillusionment to some', 'Opinion: Are foundations running state energy policy without transparency?', 'Grupo Mexico Hits Hurdle in Asarco Case 1', 'Want to go beyond your usual G&T? Here are 5 easy gin and tonic upgrades:', 'Three Deals Launched on TALF-Debut Day', 'Trump called Justin Trudeau “two-faced” after the Canadian prime minister and other world leaders appeared to talk about the U.S. president at a NATO reception', 'Opinion: While Washington is stuck in neutral, French and Dutch reformers are pushing radical change, writes @josephsternberg', 'Consumer demand for meat is surging, and supermarkets are bracing for shortages as the coronavirus forces meatpacking facilities to close', \"GM's Wagoner Will Step Down 1\", 'Ohio State president Gordon Gee will retire July 1, in the wake of recently released controversial comments.', 'Federal prosecutors say Anthony Weiner deserves about two years behind bars in his sex case', 'Prime minister Theresa May is expected to say Tuesday that the U.K. wants a clean break from the EU', 'Facing rivals with powerful mobile OS ecosystems, Amazon and Microsoft will let Alexa and Cortana talk to each other', 'When Snap said it wanted IPO investors to get powerless shares, few investors said no']\n",
            "12/07/2021 19:52:15 - INFO - __main__ -   ***** Metrics results *****\n",
            "12/07/2021 19:52:15 - INFO - __main__ -       bertscore_f1 = 0.8288924694061279\n",
            "12/07/2021 19:52:15 - INFO - __main__ -       bertscore_precision = 0.8293271660804749\n",
            "12/07/2021 19:52:15 - INFO - __main__ -       bertscore_recall = 0.8289206027984619\n",
            "12/07/2021 19:52:15 - INFO - __main__ -       bleu_score = 0.6267408410191408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HufNjkgQznG6"
      },
      "source": [
        "# Train With GloVe Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccgsAXUZz9Dp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0ad126a-0522-4b04-f82a-771ab327c8a5"
      },
      "source": [
        "!python run_lstm.py \\\n",
        "  --username \"elonmusk\" \\\n",
        "  --num_epochs 5 \\\n",
        "  --eval_every 2000 \\\n",
        "  --hidden_size 512 \\\n",
        "  --use_pretrained_embeddings True \\\n",
        "  --lr 0.0004"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/My Drive/NLP/project/dataset.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  df = df[filter]\n",
            "[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Namespace(bos_token='<BOS>', dropout=0.2, embedding_dim=300, eos_token='<EOS>', eval_every=2000, hidden_size=512, length=50, lr=0.0004, n_gpu=1, n_layers=1, no_cuda=False, num_epochs=5, output_dir='outputs', seed=42, train_split=0.8, use_pretrained_embeddings=True, username='elonmusk')\n",
            "12/03/2021 21:41:59 - INFO - __main__ -   Using pretrained twitter GloVe embeddings...\n",
            "12/03/2021 21:41:59 - INFO - torchtext.vocab.vectors -   Loading vectors from .vector_cache/glove.twitter.27B.200d.txt.pt\n",
            "12/03/2021 21:42:12 - INFO - __main__ -   [Iter 2000] Loss 7.17  Val Loss: 6.98  Val Perplexity: 1078.86\n",
            "12/03/2021 21:42:19 - INFO - __main__ -   [Iter 4000] Loss 6.29  Val Loss: 7.04  Val Perplexity: 1137.26\n",
            "12/03/2021 21:42:27 - INFO - __main__ -   [Iter 6000] Loss 5.66  Val Loss: 7.18  Val Perplexity: 1315.73\n",
            "12/03/2021 21:42:34 - INFO - __main__ -   [Iter 8000] Loss 4.87  Val Loss: 7.32  Val Perplexity: 1506.78\n",
            "12/03/2021 21:42:41 - INFO - __main__ -   [Iter 10000] Loss 4.92  Val Loss: 7.45  Val Perplexity: 1725.22\n",
            "12/03/2021 21:42:49 - INFO - __main__ -   [Iter 12000] Loss 4.14  Val Loss: 7.69  Val Perplexity: 2196.13\n",
            "12/03/2021 21:42:56 - INFO - __main__ -   ***** Eval results *****\n",
            "12/03/2021 21:42:56 - INFO - __main__ -     eval_loss = 7.660266963021744\n",
            "12/03/2021 21:42:56 - INFO - __main__ -     eval_perplexity = 2122.323934967776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLfNYPcjz-nE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a156b76f-5bb2-4155-d63d-052ada1ed9ec"
      },
      "source": [
        "!python run_lstm.py \\\n",
        "  --username \"karpathy\" \\\n",
        "  --num_epochs 5 \\\n",
        "  --eval_every 2000 \\\n",
        "  --hidden_size 512 \\\n",
        "  --use_pretrained_embeddings True \\\n",
        "  --lr 0.0004"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/My Drive/NLP/project/dataset.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  df = df[filter]\n",
            "[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Namespace(bos_token='<BOS>', dropout=0.2, embedding_dim=300, eos_token='<EOS>', eval_every=2000, hidden_size=512, length=50, lr=0.0004, n_gpu=1, n_layers=1, no_cuda=False, num_epochs=5, output_dir='outputs', seed=42, train_split=0.8, use_pretrained_embeddings=True, username='karpathy')\n",
            "12/03/2021 21:43:02 - INFO - __main__ -   Using pretrained twitter GloVe embeddings...\n",
            "12/03/2021 21:43:02 - INFO - torchtext.vocab.vectors -   Loading vectors from .vector_cache/glove.twitter.27B.200d.txt.pt\n",
            "12/03/2021 21:43:18 - INFO - __main__ -   [Iter 2000] Loss 7.26  Val Loss: 7.38  Val Perplexity: 1597.97\n",
            "12/03/2021 21:43:27 - INFO - __main__ -   [Iter 4000] Loss 6.38  Val Loss: 7.40  Val Perplexity: 1638.10\n",
            "12/03/2021 21:43:36 - INFO - __main__ -   [Iter 6000] Loss 6.31  Val Loss: 7.39  Val Perplexity: 1621.89\n",
            "12/03/2021 21:43:45 - INFO - __main__ -   [Iter 8000] Loss 5.68  Val Loss: 7.61  Val Perplexity: 2012.60\n",
            "12/03/2021 21:43:54 - INFO - __main__ -   [Iter 10000] Loss 4.89  Val Loss: 7.97  Val Perplexity: 2879.57\n",
            "12/03/2021 21:44:03 - INFO - __main__ -   [Iter 12000] Loss 4.96  Val Loss: 7.99  Val Perplexity: 2960.95\n",
            "12/03/2021 21:44:13 - INFO - __main__ -   [Iter 14000] Loss 4.17  Val Loss: 8.29  Val Perplexity: 3987.54\n",
            "12/03/2021 21:44:24 - INFO - __main__ -   ***** Eval results *****\n",
            "12/03/2021 21:44:24 - INFO - __main__ -     eval_loss = 8.304724268196455\n",
            "12/03/2021 21:44:24 - INFO - __main__ -     eval_perplexity = 4042.9272208157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD2glFkpz_sv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "564ec0c3-b7d2-40e4-be6d-db7387b6dda7"
      },
      "source": [
        "!python run_lstm.py \\\n",
        "  --username \"BarackObama\" \\\n",
        "  --num_epochs 5 \\\n",
        "  --eval_every 2000 \\\n",
        "  --hidden_size 512 \\\n",
        "  --use_pretrained_embeddings True \\\n",
        "  --lr 0.0004"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/My Drive/NLP/project/dataset.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  df = df[filter]\n",
            "[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 7000     /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Namespace(bos_token='<BOS>', dropout=0.2, embedding_dim=300, eos_token='<EOS>', eval_every=2000, hidden_size=512, length=50, lr=0.0004, n_gpu=1, n_layers=1, no_cuda=False, num_epochs=5, output_dir='outputs', seed=42, train_split=0.8, use_pretrained_embeddings=True, username='BarackObama')\n",
            "12/03/2021 21:44:31 - INFO - __main__ -   Using pretrained twitter GloVe embeddings...\n",
            "12/03/2021 21:44:31 - INFO - torchtext.vocab.vectors -   Loading vectors from .vector_cache/glove.twitter.27B.200d.txt.pt\n",
            "12/03/2021 21:44:48 - INFO - __main__ -   [Iter 2000] Loss 6.08  Val Loss: 5.91  Val Perplexity: 369.18\n",
            "12/03/2021 21:45:00 - INFO - __main__ -   [Iter 4000] Loss 5.73  Val Loss: 5.62  Val Perplexity: 276.42\n",
            "12/03/2021 21:45:11 - INFO - __main__ -   [Iter 6000] Loss 5.49  Val Loss: 5.52  Val Perplexity: 250.24\n",
            "12/03/2021 21:45:21 - INFO - __main__ -   [Iter 8000] Loss 5.32  Val Loss: 5.40  Val Perplexity: 220.92\n",
            "12/03/2021 21:45:32 - INFO - __main__ -   [Iter 10000] Loss 5.19  Val Loss: 5.25  Val Perplexity: 190.24\n",
            "12/03/2021 21:45:43 - INFO - __main__ -   [Iter 12000] Loss 4.20  Val Loss: 5.27  Val Perplexity: 193.90\n",
            "12/03/2021 21:45:54 - INFO - __main__ -   [Iter 14000] Loss 4.18  Val Loss: 5.26  Val Perplexity: 193.25\n",
            "12/03/2021 21:46:05 - INFO - __main__ -   [Iter 16000] Loss 4.18  Val Loss: 5.25  Val Perplexity: 190.89\n",
            "12/03/2021 21:46:16 - INFO - __main__ -   [Iter 18000] Loss 4.17  Val Loss: 5.23  Val Perplexity: 186.67\n",
            "12/03/2021 21:46:26 - INFO - __main__ -   [Iter 20000] Loss 4.16  Val Loss: 5.19  Val Perplexity: 180.19\n",
            "12/03/2021 21:46:37 - INFO - __main__ -   [Iter 22000] Loss 3.60  Val Loss: 5.24  Val Perplexity: 188.24\n",
            "12/03/2021 21:46:48 - INFO - __main__ -   [Iter 24000] Loss 3.56  Val Loss: 5.28  Val Perplexity: 196.44\n",
            "12/03/2021 21:46:59 - INFO - __main__ -   [Iter 26000] Loss 3.56  Val Loss: 5.26  Val Perplexity: 192.99\n",
            "12/03/2021 21:47:10 - INFO - __main__ -   [Iter 28000] Loss 3.60  Val Loss: 5.25  Val Perplexity: 190.97\n",
            "12/03/2021 21:47:21 - INFO - __main__ -   [Iter 30000] Loss 3.62  Val Loss: 5.27  Val Perplexity: 193.47\n",
            "12/03/2021 21:47:32 - INFO - __main__ -   [Iter 32000] Loss 3.62  Val Loss: 5.23  Val Perplexity: 186.12\n",
            "12/03/2021 21:47:43 - INFO - __main__ -   [Iter 34000] Loss 3.02  Val Loss: 5.31  Val Perplexity: 202.17\n",
            "12/03/2021 21:47:53 - INFO - __main__ -   [Iter 36000] Loss 3.07  Val Loss: 5.39  Val Perplexity: 218.53\n",
            "12/03/2021 21:48:04 - INFO - __main__ -   [Iter 38000] Loss 3.11  Val Loss: 5.36  Val Perplexity: 212.62\n",
            "12/03/2021 21:48:15 - INFO - __main__ -   [Iter 40000] Loss 3.14  Val Loss: 5.33  Val Perplexity: 207.11\n",
            "12/03/2021 21:48:26 - INFO - __main__ -   [Iter 42000] Loss 3.18  Val Loss: 5.35  Val Perplexity: 209.83\n",
            "12/03/2021 21:48:37 - INFO - __main__ -   [Iter 44000] Loss 2.62  Val Loss: 5.46  Val Perplexity: 235.05\n",
            "12/03/2021 21:48:48 - INFO - __main__ -   [Iter 46000] Loss 2.67  Val Loss: 5.50  Val Perplexity: 245.23\n",
            "12/03/2021 21:48:59 - INFO - __main__ -   [Iter 48000] Loss 2.71  Val Loss: 5.49  Val Perplexity: 242.81\n",
            "12/03/2021 21:49:10 - INFO - __main__ -   [Iter 50000] Loss 2.74  Val Loss: 5.52  Val Perplexity: 249.77\n",
            "12/03/2021 21:49:20 - INFO - __main__ -   [Iter 52000] Loss 2.78  Val Loss: 5.54  Val Perplexity: 254.97\n",
            "12/03/2021 21:49:35 - INFO - __main__ -   ***** Eval results *****\n",
            "12/03/2021 21:49:35 - INFO - __main__ -     eval_loss = 5.479757159394403\n",
            "12/03/2021 21:49:35 - INFO - __main__ -     eval_perplexity = 239.78846992608078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me54MpNOz3tH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6cd3412-a940-4124-9da7-7ed66c948fe8"
      },
      "source": [
        "!python run_lstm.py \\\n",
        "  --username \"cnn\" \\\n",
        "  --num_epochs 5 \\\n",
        "  --eval_every 2000 \\\n",
        "  --hidden_size 512 \\\n",
        "  --use_pretrained_embeddings True \\\n",
        "  --lr 0.0004"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/My Drive/NLP/project/dataset.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  df = df[filter]\n",
            "[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 9000     /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 19000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 27000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 31000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Namespace(bos_token='<BOS>', dropout=0.2, embedding_dim=300, eos_token='<EOS>', eval_every=2000, hidden_size=512, length=50, lr=0.0004, n_gpu=1, n_layers=1, no_cuda=False, num_epochs=5, output_dir='outputs', seed=42, train_split=0.8, use_pretrained_embeddings=True, username='cnn')\n",
            "12/03/2021 21:49:45 - INFO - __main__ -   Using pretrained twitter GloVe embeddings...\n",
            "12/03/2021 21:49:45 - INFO - torchtext.vocab.vectors -   Loading vectors from .vector_cache/glove.twitter.27B.200d.txt.pt\n",
            "12/03/2021 21:50:11 - INFO - __main__ -   [Iter 2000] Loss 7.46  Val Loss: 7.81  Val Perplexity: 2470.35\n",
            "12/03/2021 21:50:31 - INFO - __main__ -   [Iter 4000] Loss 7.26  Val Loss: 7.60  Val Perplexity: 1992.32\n",
            "12/03/2021 21:50:50 - INFO - __main__ -   [Iter 6000] Loss 7.13  Val Loss: 7.53  Val Perplexity: 1856.67\n",
            "12/03/2021 21:51:10 - INFO - __main__ -   [Iter 8000] Loss 7.05  Val Loss: 7.47  Val Perplexity: 1753.35\n",
            "12/03/2021 21:51:29 - INFO - __main__ -   [Iter 10000] Loss 6.98  Val Loss: 7.36  Val Perplexity: 1573.86\n",
            "12/03/2021 21:51:49 - INFO - __main__ -   [Iter 12000] Loss 6.92  Val Loss: 7.34  Val Perplexity: 1541.73\n",
            "12/03/2021 21:52:09 - INFO - __main__ -   [Iter 14000] Loss 6.87  Val Loss: 7.32  Val Perplexity: 1502.82\n",
            "12/03/2021 21:52:28 - INFO - __main__ -   [Iter 16000] Loss 6.82  Val Loss: 7.25  Val Perplexity: 1402.62\n",
            "12/03/2021 21:52:48 - INFO - __main__ -   [Iter 18000] Loss 6.79  Val Loss: 7.20  Val Perplexity: 1335.23\n",
            "12/03/2021 21:53:08 - INFO - __main__ -   [Iter 20000] Loss 6.75  Val Loss: 7.25  Val Perplexity: 1405.22\n",
            "12/03/2021 21:53:27 - INFO - __main__ -   [Iter 22000] Loss 6.72  Val Loss: 7.22  Val Perplexity: 1361.41\n",
            "12/03/2021 21:53:47 - INFO - __main__ -   [Iter 24000] Loss 6.69  Val Loss: 7.18  Val Perplexity: 1313.41\n",
            "12/03/2021 21:54:07 - INFO - __main__ -   [Iter 26000] Loss 5.94  Val Loss: 7.21  Val Perplexity: 1352.88\n",
            "12/03/2021 21:54:26 - INFO - __main__ -   [Iter 28000] Loss 5.92  Val Loss: 7.21  Val Perplexity: 1354.57\n",
            "12/03/2021 21:54:46 - INFO - __main__ -   [Iter 30000] Loss 5.94  Val Loss: 7.19  Val Perplexity: 1322.75\n",
            "12/03/2021 21:55:06 - INFO - __main__ -   [Iter 32000] Loss 5.94  Val Loss: 7.18  Val Perplexity: 1313.22\n",
            "12/03/2021 21:55:25 - INFO - __main__ -   [Iter 34000] Loss 5.95  Val Loss: 7.21  Val Perplexity: 1357.87\n",
            "12/03/2021 21:55:45 - INFO - __main__ -   [Iter 36000] Loss 5.95  Val Loss: 7.23  Val Perplexity: 1383.45\n",
            "12/03/2021 21:56:05 - INFO - __main__ -   [Iter 38000] Loss 5.96  Val Loss: 7.23  Val Perplexity: 1380.71\n",
            "12/03/2021 21:56:24 - INFO - __main__ -   [Iter 40000] Loss 5.97  Val Loss: 7.25  Val Perplexity: 1409.48\n",
            "12/03/2021 21:56:44 - INFO - __main__ -   [Iter 42000] Loss 5.98  Val Loss: 7.25  Val Perplexity: 1407.51\n",
            "12/03/2021 21:57:03 - INFO - __main__ -   [Iter 44000] Loss 5.99  Val Loss: 7.22  Val Perplexity: 1368.37\n",
            "12/03/2021 21:57:23 - INFO - __main__ -   [Iter 46000] Loss 5.99  Val Loss: 7.18  Val Perplexity: 1313.92\n",
            "12/03/2021 21:57:43 - INFO - __main__ -   [Iter 48000] Loss 6.00  Val Loss: 7.18  Val Perplexity: 1312.20\n",
            "12/03/2021 21:58:03 - INFO - __main__ -   [Iter 50000] Loss 5.81  Val Loss: 7.18  Val Perplexity: 1315.35\n",
            "12/03/2021 21:58:22 - INFO - __main__ -   [Iter 52000] Loss 5.41  Val Loss: 7.21  Val Perplexity: 1355.17\n",
            "12/03/2021 21:58:42 - INFO - __main__ -   [Iter 54000] Loss 5.41  Val Loss: 7.23  Val Perplexity: 1385.69\n",
            "12/03/2021 21:59:02 - INFO - __main__ -   [Iter 56000] Loss 5.43  Val Loss: 7.28  Val Perplexity: 1448.21\n",
            "12/03/2021 21:59:21 - INFO - __main__ -   [Iter 58000] Loss 5.45  Val Loss: 7.27  Val Perplexity: 1441.85\n",
            "12/03/2021 21:59:41 - INFO - __main__ -   [Iter 60000] Loss 5.47  Val Loss: 7.31  Val Perplexity: 1502.59\n",
            "12/03/2021 22:00:01 - INFO - __main__ -   [Iter 62000] Loss 5.48  Val Loss: 7.30  Val Perplexity: 1480.09\n",
            "12/03/2021 22:00:20 - INFO - __main__ -   [Iter 64000] Loss 5.51  Val Loss: 7.31  Val Perplexity: 1496.86\n",
            "12/03/2021 22:00:40 - INFO - __main__ -   [Iter 66000] Loss 5.53  Val Loss: 7.31  Val Perplexity: 1497.64\n",
            "12/03/2021 22:01:00 - INFO - __main__ -   [Iter 68000] Loss 5.55  Val Loss: 7.29  Val Perplexity: 1467.90\n",
            "12/03/2021 22:01:19 - INFO - __main__ -   [Iter 70000] Loss 5.57  Val Loss: 7.30  Val Perplexity: 1484.71\n",
            "12/03/2021 22:01:39 - INFO - __main__ -   [Iter 72000] Loss 5.59  Val Loss: 7.33  Val Perplexity: 1517.99\n",
            "12/03/2021 22:01:58 - INFO - __main__ -   [Iter 74000] Loss 5.60  Val Loss: 7.31  Val Perplexity: 1491.24\n",
            "12/03/2021 22:02:18 - INFO - __main__ -   [Iter 76000] Loss 4.86  Val Loss: 7.39  Val Perplexity: 1613.74\n",
            "12/03/2021 22:02:38 - INFO - __main__ -   [Iter 78000] Loss 4.90  Val Loss: 7.42  Val Perplexity: 1675.51\n",
            "12/03/2021 22:02:57 - INFO - __main__ -   [Iter 80000] Loss 4.95  Val Loss: 7.43  Val Perplexity: 1692.39\n",
            "12/03/2021 22:03:17 - INFO - __main__ -   [Iter 82000] Loss 4.99  Val Loss: 7.43  Val Perplexity: 1683.60\n",
            "12/03/2021 22:03:37 - INFO - __main__ -   [Iter 84000] Loss 5.03  Val Loss: 7.46  Val Perplexity: 1732.63\n",
            "12/03/2021 22:03:56 - INFO - __main__ -   [Iter 86000] Loss 5.06  Val Loss: 7.46  Val Perplexity: 1730.22\n",
            "12/03/2021 22:04:16 - INFO - __main__ -   [Iter 88000] Loss 5.08  Val Loss: 7.48  Val Perplexity: 1768.57\n",
            "12/03/2021 22:04:36 - INFO - __main__ -   [Iter 90000] Loss 5.11  Val Loss: 7.48  Val Perplexity: 1772.24\n",
            "12/03/2021 22:04:55 - INFO - __main__ -   [Iter 92000] Loss 5.14  Val Loss: 7.44  Val Perplexity: 1708.22\n",
            "12/03/2021 22:05:15 - INFO - __main__ -   [Iter 94000] Loss 5.16  Val Loss: 7.45  Val Perplexity: 1713.62\n",
            "12/03/2021 22:05:35 - INFO - __main__ -   [Iter 96000] Loss 5.19  Val Loss: 7.45  Val Perplexity: 1726.12\n",
            "12/03/2021 22:05:54 - INFO - __main__ -   [Iter 98000] Loss 5.21  Val Loss: 7.46  Val Perplexity: 1734.71\n",
            "12/03/2021 22:06:14 - INFO - __main__ -   [Iter 100000] Loss 4.60  Val Loss: 7.46  Val Perplexity: 1736.26\n",
            "12/03/2021 22:06:34 - INFO - __main__ -   [Iter 102000] Loss 4.47  Val Loss: 7.56  Val Perplexity: 1926.00\n",
            "12/03/2021 22:06:53 - INFO - __main__ -   [Iter 104000] Loss 4.51  Val Loss: 7.59  Val Perplexity: 1974.32\n",
            "12/03/2021 22:07:13 - INFO - __main__ -   [Iter 106000] Loss 4.55  Val Loss: 7.62  Val Perplexity: 2032.29\n",
            "12/03/2021 22:07:33 - INFO - __main__ -   [Iter 108000] Loss 4.59  Val Loss: 7.61  Val Perplexity: 2025.21\n",
            "12/03/2021 22:07:52 - INFO - __main__ -   [Iter 110000] Loss 4.62  Val Loss: 7.62  Val Perplexity: 2031.28\n",
            "12/03/2021 22:08:12 - INFO - __main__ -   [Iter 112000] Loss 4.66  Val Loss: 7.64  Val Perplexity: 2079.69\n",
            "12/03/2021 22:08:32 - INFO - __main__ -   [Iter 114000] Loss 4.69  Val Loss: 7.62  Val Perplexity: 2045.69\n",
            "12/03/2021 22:08:52 - INFO - __main__ -   [Iter 116000] Loss 4.73  Val Loss: 7.62  Val Perplexity: 2042.89\n",
            "12/03/2021 22:09:11 - INFO - __main__ -   [Iter 118000] Loss 4.76  Val Loss: 7.59  Val Perplexity: 1969.69\n",
            "12/03/2021 22:09:31 - INFO - __main__ -   [Iter 120000] Loss 4.79  Val Loss: 7.62  Val Perplexity: 2039.36\n",
            "12/03/2021 22:09:51 - INFO - __main__ -   [Iter 122000] Loss 4.82  Val Loss: 7.60  Val Perplexity: 2001.81\n",
            "12/03/2021 22:10:10 - INFO - __main__ -   [Iter 124000] Loss 4.85  Val Loss: 7.62  Val Perplexity: 2037.00\n",
            "12/03/2021 22:10:30 - INFO - __main__ -   ***** Eval results *****\n",
            "12/03/2021 22:10:30 - INFO - __main__ -     eval_loss = 7.5901734711837765\n",
            "12/03/2021 22:10:30 - INFO - __main__ -     eval_perplexity = 1978.6567239008878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xelcHNNZz5WA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06ac8a6-82e0-4f53-ff8a-b39a1b17400b"
      },
      "source": [
        "!python run_lstm.py \\\n",
        "  --username \"wsj\" \\\n",
        "  --num_epochs 5 \\\n",
        "  --eval_every 2000 \\\n",
        "  --hidden_size 512 \\\n",
        "  --use_pretrained_embeddings True \\\n",
        "  --lr 0.0004"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/My Drive/NLP/project/dataset.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  df = df[filter]\n",
            "[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 9000     /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 17000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 23000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 28000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Namespace(bos_token='<BOS>', dropout=0.2, embedding_dim=300, eos_token='<EOS>', eval_every=2000, hidden_size=512, length=50, lr=0.0004, n_gpu=1, n_layers=1, no_cuda=False, num_epochs=5, output_dir='outputs', seed=42, train_split=0.8, use_pretrained_embeddings=True, username='wsj')\n",
            "12/03/2021 22:10:40 - INFO - __main__ -   Using pretrained twitter GloVe embeddings...\n",
            "12/03/2021 22:10:40 - INFO - torchtext.vocab.vectors -   Loading vectors from .vector_cache/glove.twitter.27B.200d.txt.pt\n",
            "12/03/2021 22:11:05 - INFO - __main__ -   [Iter 2000] Loss 7.63  Val Loss: 7.35  Val Perplexity: 1560.03\n",
            "12/03/2021 22:11:24 - INFO - __main__ -   [Iter 4000] Loss 7.41  Val Loss: 7.17  Val Perplexity: 1301.79\n",
            "12/03/2021 22:11:43 - INFO - __main__ -   [Iter 6000] Loss 7.28  Val Loss: 7.07  Val Perplexity: 1172.93\n",
            "12/03/2021 22:12:02 - INFO - __main__ -   [Iter 8000] Loss 7.18  Val Loss: 7.00  Val Perplexity: 1095.43\n",
            "12/03/2021 22:12:21 - INFO - __main__ -   [Iter 10000] Loss 7.12  Val Loss: 6.91  Val Perplexity: 1004.50\n",
            "12/03/2021 22:12:40 - INFO - __main__ -   [Iter 12000] Loss 7.06  Val Loss: 6.88  Val Perplexity: 969.29\n",
            "12/03/2021 22:12:59 - INFO - __main__ -   [Iter 14000] Loss 7.01  Val Loss: 6.84  Val Perplexity: 934.12\n",
            "12/03/2021 22:13:17 - INFO - __main__ -   [Iter 16000] Loss 6.97  Val Loss: 6.80  Val Perplexity: 896.07\n",
            "12/03/2021 22:13:36 - INFO - __main__ -   [Iter 18000] Loss 6.94  Val Loss: 6.79  Val Perplexity: 890.04\n",
            "12/03/2021 22:13:55 - INFO - __main__ -   [Iter 20000] Loss 6.90  Val Loss: 6.75  Val Perplexity: 853.20\n",
            "12/03/2021 22:14:14 - INFO - __main__ -   [Iter 22000] Loss 6.87  Val Loss: 6.72  Val Perplexity: 828.84\n",
            "12/03/2021 22:14:33 - INFO - __main__ -   [Iter 24000] Loss 6.05  Val Loss: 6.77  Val Perplexity: 871.37\n",
            "12/03/2021 22:14:52 - INFO - __main__ -   [Iter 26000] Loss 6.05  Val Loss: 6.80  Val Perplexity: 897.67\n",
            "12/03/2021 22:15:11 - INFO - __main__ -   [Iter 28000] Loss 6.08  Val Loss: 6.81  Val Perplexity: 911.06\n",
            "12/03/2021 22:15:30 - INFO - __main__ -   [Iter 30000] Loss 6.08  Val Loss: 6.78  Val Perplexity: 878.93\n",
            "12/03/2021 22:15:49 - INFO - __main__ -   [Iter 32000] Loss 6.09  Val Loss: 6.77  Val Perplexity: 875.62\n",
            "12/03/2021 22:16:08 - INFO - __main__ -   [Iter 34000] Loss 6.10  Val Loss: 6.81  Val Perplexity: 902.50\n",
            "12/03/2021 22:16:26 - INFO - __main__ -   [Iter 36000] Loss 6.11  Val Loss: 6.77  Val Perplexity: 870.91\n",
            "12/03/2021 22:16:45 - INFO - __main__ -   [Iter 38000] Loss 6.11  Val Loss: 6.76  Val Perplexity: 866.39\n",
            "12/03/2021 22:17:04 - INFO - __main__ -   [Iter 40000] Loss 6.12  Val Loss: 6.75  Val Perplexity: 849.91\n",
            "12/03/2021 22:17:23 - INFO - __main__ -   [Iter 42000] Loss 6.13  Val Loss: 6.76  Val Perplexity: 862.60\n",
            "12/03/2021 22:17:42 - INFO - __main__ -   [Iter 44000] Loss 6.14  Val Loss: 6.74  Val Perplexity: 846.29\n",
            "12/03/2021 22:18:01 - INFO - __main__ -   [Iter 46000] Loss 6.14  Val Loss: 6.73  Val Perplexity: 836.28\n",
            "12/03/2021 22:18:20 - INFO - __main__ -   [Iter 48000] Loss 5.53  Val Loss: 6.75  Val Perplexity: 850.84\n",
            "12/03/2021 22:18:38 - INFO - __main__ -   [Iter 50000] Loss 5.51  Val Loss: 6.79  Val Perplexity: 892.33\n",
            "12/03/2021 22:18:57 - INFO - __main__ -   [Iter 52000] Loss 5.52  Val Loss: 6.83  Val Perplexity: 924.06\n",
            "12/03/2021 22:19:16 - INFO - __main__ -   [Iter 54000] Loss 5.54  Val Loss: 6.85  Val Perplexity: 939.77\n",
            "12/03/2021 22:19:35 - INFO - __main__ -   [Iter 56000] Loss 5.57  Val Loss: 6.82  Val Perplexity: 917.07\n",
            "12/03/2021 22:19:54 - INFO - __main__ -   [Iter 58000] Loss 5.60  Val Loss: 6.86  Val Perplexity: 949.68\n",
            "12/03/2021 22:20:13 - INFO - __main__ -   [Iter 60000] Loss 5.62  Val Loss: 6.84  Val Perplexity: 931.87\n",
            "12/03/2021 22:20:32 - INFO - __main__ -   [Iter 62000] Loss 5.63  Val Loss: 6.85  Val Perplexity: 942.10\n",
            "12/03/2021 22:20:51 - INFO - __main__ -   [Iter 64000] Loss 5.66  Val Loss: 6.84  Val Perplexity: 931.68\n",
            "12/03/2021 22:21:09 - INFO - __main__ -   [Iter 66000] Loss 5.68  Val Loss: 6.82  Val Perplexity: 915.76\n",
            "12/03/2021 22:21:28 - INFO - __main__ -   [Iter 68000] Loss 5.70  Val Loss: 6.83  Val Perplexity: 927.39\n",
            "12/03/2021 22:21:47 - INFO - __main__ -   [Iter 70000] Loss 5.71  Val Loss: 6.83  Val Perplexity: 926.47\n",
            "12/03/2021 22:22:06 - INFO - __main__ -   [Iter 72000] Loss 4.99  Val Loss: 6.90  Val Perplexity: 994.21\n",
            "12/03/2021 22:22:25 - INFO - __main__ -   [Iter 74000] Loss 5.02  Val Loss: 6.92  Val Perplexity: 1016.85\n",
            "12/03/2021 22:22:43 - INFO - __main__ -   [Iter 76000] Loss 5.05  Val Loss: 6.95  Val Perplexity: 1038.92\n",
            "12/03/2021 22:23:02 - INFO - __main__ -   [Iter 78000] Loss 5.08  Val Loss: 6.94  Val Perplexity: 1032.94\n",
            "12/03/2021 22:23:21 - INFO - __main__ -   [Iter 80000] Loss 5.12  Val Loss: 6.98  Val Perplexity: 1070.48\n",
            "12/03/2021 22:23:40 - INFO - __main__ -   [Iter 82000] Loss 5.16  Val Loss: 6.94  Val Perplexity: 1034.11\n",
            "12/03/2021 22:23:59 - INFO - __main__ -   [Iter 84000] Loss 5.19  Val Loss: 6.95  Val Perplexity: 1045.74\n",
            "12/03/2021 22:24:17 - INFO - __main__ -   [Iter 86000] Loss 5.23  Val Loss: 6.93  Val Perplexity: 1023.42\n",
            "12/03/2021 22:24:36 - INFO - __main__ -   [Iter 88000] Loss 5.25  Val Loss: 6.94  Val Perplexity: 1032.47\n",
            "12/03/2021 22:24:55 - INFO - __main__ -   [Iter 90000] Loss 5.28  Val Loss: 6.96  Val Perplexity: 1048.56\n",
            "12/03/2021 22:25:14 - INFO - __main__ -   [Iter 92000] Loss 5.30  Val Loss: 6.95  Val Perplexity: 1047.14\n",
            "12/03/2021 22:25:33 - INFO - __main__ -   [Iter 94000] Loss 5.33  Val Loss: 6.96  Val Perplexity: 1051.31\n",
            "12/03/2021 22:25:52 - INFO - __main__ -   [Iter 96000] Loss 4.59  Val Loss: 7.04  Val Perplexity: 1136.63\n",
            "12/03/2021 22:26:10 - INFO - __main__ -   [Iter 98000] Loss 4.59  Val Loss: 7.06  Val Perplexity: 1165.29\n",
            "12/03/2021 22:26:29 - INFO - __main__ -   [Iter 100000] Loss 4.64  Val Loss: 7.09  Val Perplexity: 1201.81\n",
            "12/03/2021 22:26:48 - INFO - __main__ -   [Iter 102000] Loss 4.69  Val Loss: 7.11  Val Perplexity: 1220.88\n",
            "12/03/2021 22:27:07 - INFO - __main__ -   [Iter 104000] Loss 4.73  Val Loss: 7.14  Val Perplexity: 1255.48\n",
            "12/03/2021 22:27:26 - INFO - __main__ -   [Iter 106000] Loss 4.77  Val Loss: 7.12  Val Perplexity: 1235.30\n",
            "12/03/2021 22:27:44 - INFO - __main__ -   [Iter 108000] Loss 4.81  Val Loss: 7.09  Val Perplexity: 1196.22\n",
            "12/03/2021 22:28:03 - INFO - __main__ -   [Iter 110000] Loss 4.84  Val Loss: 7.14  Val Perplexity: 1258.01\n",
            "12/03/2021 22:28:22 - INFO - __main__ -   [Iter 112000] Loss 4.88  Val Loss: 7.14  Val Perplexity: 1263.72\n",
            "12/03/2021 22:28:41 - INFO - __main__ -   [Iter 114000] Loss 4.91  Val Loss: 7.10  Val Perplexity: 1212.56\n",
            "12/03/2021 22:29:00 - INFO - __main__ -   [Iter 116000] Loss 4.94  Val Loss: 7.09  Val Perplexity: 1203.91\n",
            "12/03/2021 22:29:24 - INFO - __main__ -   ***** Eval results *****\n",
            "12/03/2021 22:29:24 - INFO - __main__ -     eval_loss = 7.10003315632121\n",
            "12/03/2021 22:29:24 - INFO - __main__ -     eval_perplexity = 1212.0072595283848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3x3i0sM9tYa"
      },
      "source": [
        "## Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VI8br9F9tYa",
        "outputId": "15da8b24-f544-48da-debd-9dccecdffac4"
      },
      "source": [
        "!python run_lstm_generation.py \\\n",
        "  --username \"elonmusk\" \\\n",
        "  --num_sequences 10 \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --seed 52"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/03/2021 22:29:34 - INFO - __main__ -   Sample 0: At test flight legs about climate on Monday. This is real →?\n",
            "12/03/2021 22:29:34 - INFO - __main__ -   Sample 1: \n",
            "12/03/2021 22:29:34 - INFO - __main__ -   Sample 2: Tesla Model X video a release Powerwall car ever in the Atlantic\n",
            "12/03/2021 22:29:34 - INFO - __main__ -   Sample 3: \n",
            "12/03/2021 22:29:34 - INFO - __main__ -   Sample 4: Landing Tesla patents\n",
            "12/03/2021 22:29:34 - INFO - __main__ -   Sample 5: First video rocket factory in Texas\n",
            "12/03/2021 22:29:34 - INFO - __main__ -   Sample 6: The first launch is deleting live in Instructions )\n",
            "12/03/2021 22:29:34 - INFO - __main__ -   Sample 7: My upgrade details\n",
            "12/03/2021 22:29:34 - INFO - __main__ -   Sample 8: Model 3 Performance\n",
            "12/03/2021 22:29:34 - INFO - __main__ -   Sample 9: I want I can never\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvqboLvH9tYa",
        "outputId": "9fd82a20-b3c8-44a0-cf5a-536292b36ac7"
      },
      "source": [
        "!python run_lstm_generation.py \\\n",
        "  --username \"karpathy\" \\\n",
        "  --num_sequences 10 \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --seed 52"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/03/2021 22:29:44 - INFO - __main__ -   Sample 0: A company imagines of my nostalgia and Deep Learning from Joan Bruna on the trenches # icra2013 # sorrow 1\n",
            "12/03/2021 22:29:44 - INFO - __main__ -   Sample 1: This is what for a bit but I' m starting a very corner. I like a bug for the PhD liaison :\n",
            "12/03/2021 22:29:44 - INFO - __main__ -   Sample 2: Nice roundup of my nostalgia from Google talk by MIT CSAIL I can a lot that of the research here of code favorites :\n",
            "12/03/2021 22:29:44 - INFO - __main__ -   Sample 3: I put up a bit more articles from 1800msfwdbwd than a lot of ago, I' m trying to realize that with his. Fun to train\n",
            "12/03/2021 22:29:44 - INFO - __main__ -   Sample 4: Working one of a cat of the brain in the politics of entertainment\n",
            "12/03/2021 22:29:44 - INFO - __main__ -   Sample 5: Also a nice idea from ECCV on a day - scale manufacturing. I want to spread on Vine, but I' m a few bug of 1\n",
            "12/03/2021 22:29:44 - INFO - __main__ -   Sample 6: I feel all the new ones. I have a bit. I' m supposed about it' s the best head of code and received ) of this\n",
            "12/03/2021 22:29:44 - INFO - __main__ -   Sample 7: I' m doing new about for training, but I think I' m so happy on my hands. I' m very good to go.\n",
            "12/03/2021 22:29:44 - INFO - __main__ -   Sample 8: \" Why company Vision Meets \" Deep Learning : \" A Productivity : \" Is \" it' s fairly well!\n",
            "12/03/2021 22:29:44 - INFO - __main__ -   Sample 9: A cool roundup of images with Neural Networks the internet :\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clKtZHbo9tYa",
        "outputId": "60fa8b4a-c242-4be4-88c5-c80f1853d71e"
      },
      "source": [
        "!python run_lstm_generation.py \\\n",
        "  --username \"BarackObama\" \\\n",
        "  --num_sequences 10 \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --seed 52"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/03/2021 22:29:53 - INFO - __main__ -   Sample 0: President Obama : \" We know what change looks like because of the most important that has come roaring to be a.\" - passed President Obama\n",
            "12/03/2021 22:29:53 - INFO - __main__ -   Sample 1: \" We' ve got to make sure that every American is heard when they' ve got to work for us all gun.\" — President Obama\n",
            "12/03/2021 22:29:53 - INFO - __main__ -   Sample 2: “ We know that we can be as one nation we can keep moving forward. We ’ re going to get out the vote this year.\" # SOTU\n",
            "12/03/2021 22:29:53 - INFO - __main__ -   Sample 3: At an \" America' s second event meeting for President Obama in Chicago :\n",
            "12/03/2021 22:29:53 - INFO - __main__ -   Sample 4: If you' re proud of what health care reform, add your name :\n",
            "12/03/2021 22:29:53 - INFO - __main__ -   Sample 5: In New York, IN at the State of the Union. We watch. Watch live at\n",
            "12/03/2021 22:29:53 - INFO - __main__ -   Sample 6: \" I want to make sure every person, the American people can make a difference in this country.\" — President Obama # SOTU\n",
            "12/03/2021 22:29:53 - INFO - __main__ -   Sample 7: A special West Wing Week from Sudan :\n",
            "12/03/2021 22:29:53 - INFO - __main__ -   Sample 8: President Obama : “ We know that our country is stronger when everybody when we should let Detroit go bankrupt. We ’ ve got more work to do. We keep moving forward.”\n",
            "12/03/2021 22:29:53 - INFO - __main__ -   Sample 9: This is a big choice for women in your name :\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJS3GPtT9tYb",
        "outputId": "995504d9-3f12-4700-ed0f-f80831c5788b"
      },
      "source": [
        "!python run_lstm_generation.py \\\n",
        "  --username \"cnn\" \\\n",
        "  --num_sequences 10 \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --seed 52"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/03/2021 22:30:02 - INFO - __main__ -   Sample 0: Obama to call for school assault.\n",
            "12/03/2021 22:30:02 - INFO - __main__ -   Sample 1: Judge OKs Casey Anthony released from hospital after collapse - year - old.\n",
            "12/03/2021 22:30:02 - INFO - __main__ -   Sample 2: What ’ s your favorite with? @ Bourdain goes to the new few. He' s # gottadoit # vs. @ AC360\n",
            "12/03/2021 22:30:02 - INFO - __main__ -   Sample 3: Police : An of' d boy' to be shot, 1 dead in 2\n",
            "12/03/2021 22:30:02 - INFO - __main__ -   Sample 4: ' Study new' for action.\n",
            "12/03/2021 22:30:02 - INFO - __main__ -   Sample 5: Obama : Clinton in potentially with U. S. official says.\n",
            "12/03/2021 22:30:02 - INFO - __main__ -   Sample 6: First, is speaking now at the Olympics. @ Bourdain is on # January tonight, 9pm ET.\n",
            "12/03/2021 22:30:02 - INFO - __main__ -   Sample 7: ' Passengers of Man' in Polls - death, after' s killing of dead, dies at 7\n",
            "12/03/2021 22:30:02 - INFO - __main__ -   Sample 8: ' Pirates Is' for Obama on his speech.\n",
            "12/03/2021 22:30:02 - INFO - __main__ -   Sample 9: NASA CNN Gadhafi on CNN. comLive : Obama' s' health care bill' for freedom.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYyyDRbZ9tYb",
        "outputId": "7712d5ac-d18a-4c45-f7f7-43fab1b5506b"
      },
      "source": [
        "!python run_lstm_generation.py \\\n",
        "  --username \"wsj\" \\\n",
        "  --num_sequences 10 \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --seed 52"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/03/2021 22:30:11 - INFO - __main__ -   Sample 0: Opinion : The SEC behind shooting back on survive ’ s capital - - Russia rule for an IPO\n",
            "12/03/2021 22:30:11 - INFO - __main__ -   Sample 1: The new rate - service for an hour of California :\n",
            "12/03/2021 22:30:11 - INFO - __main__ -   Sample 2: New York Times s new technology to pay up their 10 - year - old on the market.\n",
            "12/03/2021 22:30:11 - INFO - __main__ -   Sample 3: The U. S. has is since a deal to lead the Fed ’ s largest companies - day after Sandy\n",
            "12/03/2021 22:30:11 - INFO - __main__ -   Sample 4: Breaking : U. S. Postal Service said it will buy interest rates low - wage tax overhaul\n",
            "12/03/2021 22:30:11 - INFO - __main__ -   Sample 5: The battle for America' s most - largest - ever by a group of week\n",
            "12/03/2021 22:30:11 - INFO - __main__ -   Sample 6: Opinion : Trump ’ s tax cuts in House would Senate the list of Fed markets leader\n",
            "12/03/2021 22:30:11 - INFO - __main__ -   Sample 7: A group of the world' s largest tech companies, China ’ s biggest tech companies are struggling to fall\n",
            "12/03/2021 22:30:11 - INFO - __main__ -   Sample 8: The Dow Jones Industrial Average points after the World Cup of the highest level since the year after the company' s stock\n",
            "12/03/2021 22:30:11 - INFO - __main__ -   Sample 9: The most powerful hurricanes in the NBA' s, and a top - security coverage of the world :\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "G6A9v-AOmylc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_lstm_metrics.py \\\n",
        "  --username \"elonmusk\" \\\n",
        "  --test_data_file \"data/elonmusk/test.txt\" \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --with_glove True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYYR4TsDmz7v",
        "outputId": "28a88e24-b2b5-4e50-eb03-7924621fd38d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "['Snowed to see in the Fermi Paradox', 'Ok Tesla Model S by @ConsumerReports!', 'Climate the Westworld of Tesla of dual motor by the International Space Station planned time', 'Paid in California', 'That Tesla is dual motor & a cover in NY is it almost \" a Best CEOs', 'Simulations on the moon', \"Don't fool ur Vibe m. I hope.\", 'Tesla Solarglass vs Happy Halloween!!', 'New Tesla Model X review by @MotorTrend at', 'Attempting at', 'Painting in red of Dragon. This is much appreciated than a show car on this.', '78 % the Gigafactory of our Grasshopper VTVL for Tesla to fly with a little Model 3', \"Not Mom is all. Picotech, this really matters, then' s why. #DareToExplore\", 'Just want there Starship at the Gigafactory of the media Space Station pack?', 'Falcon Heavy goes vertical', 'This is so to build', 'Star rocket Texas', \"Don't Doubt ur Vibe m\", 'Got Tesla is actually to see that it is just a syndrome', 'Flight', 'Moving a Model S on the Gigafactory', '…', 'Model X review', 'Activists', 'Sleeving of the kind hangar that of the SpaceX spacecraft satellite at pm California', 'Expect heh', \"Happy is alive, but the this isn' t do\", 'Falcon 9 rocket LZ launch vertical of time at Cape Canaveral', 'Cybertruck pulls F - 150 uphill', 'Aspirationally on the moon', 'Dragon Tesla Supercharger unveil 285', 'Good Tesla @SolarCity!', 'Glad - Tesla short', 'Last at', 'Extreme is an amazing was good!', 'Deus on the moon', 'Holding of the @SpaceX Interplanetary Spaceship by @NASASpaceflight', 'Just wanted', 'Model X review by Motor Trend', 'Tesla Moth by @nytimes', 'Dragon the future Tesla of the Gigafactory', 'Socialism', 'Not Mom by @SpaceX', 'Saw of Falcon Heavy @SpaceX Dragon announcement', \"Happy's pretty much appreciated happened\", 'Three', 'The lady doth protest the Fermi Paradox', 'Mission …', 'Told is magic for awesome.', 'Wish']\n",
            "['Snowed in at Mt. Rushmore @GoParks', 'Ok u can have a little emerald', 'Climate change deniers claim \"scientists disagree\", same rebuttal used by tobacco industry about lung cancer for decades', 'Paid respects to Masada earlier today. Live free or die.', 'That was a total non sequitur btw', 'Simulations show launch ok with bad valve. Still, better to stop & fix. Recalling rockets after launch is not an option.', 'Don’t Doubt ur Vibe m.', 'Tesla should have a mega rave cave under the Berlin Gigafatory', 'New Tesla referral program just released', 'Attempting bring up of thruster pods 2 and 4', 'Painting the name on the droneship ...', '78% of people want to gentrify Mordor', 'Not having a big gas guzzler engine in front means there’s room for trunks in front & back, plus longer crumple zone for best safety of any midsize car It’s crazy how much stuff fits in a Model 3 twitter.comAlguireTimsta…', 'Just wanted to say thanks to everyone for testifying yesterday in Austin. Will hang around after press conf to thank people in person.', 'Falcon 9 lifting off with 1.3 mmmillion pounds of force', 'This is nothing. In a few years, that bot will move so fast you’ll need a strobe light to see it. Sweet dreams… we dead', 'Star Light, Star Bright', 'Don’t defy DeFi', 'Got to regulate AIrobotics like we do food, drugs, aircraft & cars. Public risks require public oversight. Getting rid of the FAA wdn’t make flying safer. They’re there for good reason.', 'Flight computer aborted rocket hold down firing. Anomaly addressed. Cycling systems to countdown', \"Moving at ~23 times speed of sound, circling Earth every ~90 minutes View of an orbital sunset from Dragon's cupola\", '… going to moon very soon', 'Model S options are out! Performance in red and black for me. I will deliver my car in JuneJuly.', 'Activists should be pushing for more moderates to advise President, not fewer. How could having only extremists advise him possibly be good?', 'Sleeving SN2 dome in the high bay', 'Expect to reach preliminary conclusions regarding last flight by end of week. Will brief key customers & FAA, then post on our website.', 'Happy 4th of July!!', 'Falcon Heavy side boosters can use most of the same airframe as Falcon 9, but center core needs to be buffed up a lot for transfer loads.', 'Cybertruck prototype in New York this weekend', 'Aspirationally acerbic alliteration -> Bullshit baffles brains', 'Dragon will travel from south of New Zealand to Florida in ~37 minutes', 'Good article on the interplanetary transport system on Gizmodo', 'Glad you’re ok @tylerthecreator', 'Last known state for rocket boost stage is 360 ms, Mach 1.1, 8.5 km altitude and roll rate close to zero (v important!)', 'Extreme wind shear over Cape Canaveral. Feels like a sledgehammer when supersonic in the vertical. Hoping it changes …', 'Deus ex machine learning', 'Holding on solar array deployment until at least two thruster pods are active', 'Just fired our Superdraco escape rocket engine at full thrust! Needed to carry astronauts on Dragon', 'Model S Signature series sold out as of today', 'Tesla Solar just relaunched. Lmk what you think …', 'Dragon 2 is designed to be able to land anywhere in the solar system. Red Dragon Mars mission is the first test flight.', 'Socialism vs capitalism is not even the right question. What really matters is avoiding monopolies that restrict people’s freedom.', 'Not that this really matters. All current rocket tech, including ours, sucks. Only when it becomes fully reusable, will it not suck.', \"Saw The Dictator yesterday. Reminded me of Putin's reelection. Seems like only yesterday since he was last in power.\", 'Happy Thanksgiving!', 'Three Raptors on a Starship', 'The Model S beta endurance car just passed 150,000 miles on a single battery pack!', 'Mission looks good. Started deploying the 10 Iridium satellites. Rocket is stable on the droneship.', 'Told you AI was dangerous!! Massive semen explosion after blaze hits bull artificial insemination facility, firefighters forced to dodge \"projectiles\"', 'Wish there was something we could do to help the people of Syria.']\n",
            "True\n",
            "12/07/2021 20:37:48 - INFO - __main__ -   ***** Metrics results *****\n",
            "12/07/2021 20:37:48 - INFO - __main__ -       bertscore_f1 = 0.8259861469268799\n",
            "12/07/2021 20:37:48 - INFO - __main__ -       bertscore_precision = 0.8317878842353821\n",
            "12/07/2021 20:37:48 - INFO - __main__ -       bertscore_recall = 0.8209657073020935\n",
            "12/07/2021 20:37:48 - INFO - __main__ -       bleu_score = 0.6864740199582415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_lstm_metrics.py \\\n",
        "  --username \"karpathy\" \\\n",
        "  --test_data_file \"data/karpathy/test.txt\" \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --with_glove True \\\n",
        "  --seed 120"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3L1hyQenbkM",
        "outputId": "4cf5c105-e38c-4ab5-a4f2-0e6e3585d252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[\"Up' t know how, but you take it you must get it would be your as a blog for the next of time time for ask. It' s a bit distracting.\", 'RE: \" It\\' s new \" A man is the norm of a short who stare up from @prismatic', \"I' m reviewing of the dial with my life on one and fun. I keep like a lot ago. I was Given a small. 1\", 'A friend on the Sciences - their robo - 3D - based - nukes dangers in 23 mults. They they', \"Yummy to program from @j26774 is a bit to be my own. I think I' m trying to go for the marks of my utility. I think I feel like the direction.\", 'Recurrent aborted??', 'My networking is now, we\\' re \" Neural Networks to work \" I don\\' t make some to use to start in my pocket.', '3D reconstruction on nanoscales and: D your The Year of DIY in related\\' \" A book:)', 'Speech2Face: Why serialization of papers ( see ) is hindered a the interview ). on this:', \"I was new CD to write the unsupervised demo, by @MaxCRoser ( on, I' m reading to make this when be to work more info for our freedom\", \"Congrats of what data I' m trying to see this, but how much feel of these papers last few years ago. But will be here.\", 'Awesome: A DIY of a video ( also ) is ) is a thing at MIT CSAIL.', \"Working - more: GIFs with many and made it' s kinda ( via @NandoDF )\", \"Computer Vision Lenna' s a cool of a CS! ( see ) is joining a few - 2 days ago\", 'Kickstarter a lot of the interview in the Standard. ( via @lorenzoriano )', 'A Compilation on the CMU exodus: I have to admit them - this morning.', 'A Peek from Semi on \" - Unreasonable processors:', \"I have a Lorenz Attractor on the IDE and yesterday I still. I was a fan that I thought up in I was you can' t know 1\", \"Google Reader is shutting down, I missed this, but that' s too to see this game ).\", \"Wingsuit' t wait this to be what but I stumbled this it' s really hard to read, then it' s a known bug deal: D\", 'Haha: New Zealand video on Vine - level human gallops at 40m as a few years ago', 'Research: Word2vec video on 3 to, users and now Workshop. The Internship video', '\" The Unreasonable Effectiveness of \" A has the trenches \" is becoming with a of \" departmental \" in context, I\\' m so excited of this', 'is one best of few days ago, 000 mark to speed lab a Pope - level during. Not sure about what', 'By Vide my way to stay nicely of the day.', 'Ideally of Google of the brain:', 'I added the last week on Netflix from RSS and setup, I Googled, 000 this is the best 2', 'A misconception of neural nets I have to spend \" cool \" the World \", \" I must I was wanted it right too now for', 'Sitting by awesome AMA', 'This is really nice! 1', 'Visited Kinect.', 'Wednesday, so\\' s alright to see transformers of a lecture \". I feel it all a brilliant. I\\' m now this', \"Programming this is a thing of my favorite. It' s a fairly of YouTube for a whole.\", \"ICLR, I' m in a new about the lab. I guess it' s just a very nice, I' m getting at the same though, but you feel it it 1\", \"Does Passing else anthropomorphize a few thousand to the imminent class by Wired. It' s a bit of it for\", 'Wow: The Hobbit of Life ( via @bracelet )', \"I' m supposed to what a ConvNet party at MIT Media Lab on the way. I' m reading to more chemistrymathsims. I remember a lot of them, but it' s alright.\", 'Hmm. I\\' m trying to make writing this, but what it\\' s a song distracting on \" I have it took of \" partnership in povertyviolencehealtheducation is in best as 1', \"yay - engineering new of my favorite, but I feel the lab I' ve been it! 2\", 'My temporary out of the brain \" in our of Computer Vision, a very nicely to be homeless', 'Former example that I missed through I like this by the way of my day', 'My adviser blog post from @prismatic on their dog in the iPhone of last week', 'Why are the serialization is the junk from a big type in the office of using in a few months \"', \"hah, I' m a few nice that I lived that my net to get through my life.\", \"I don' t know what we' re at this, but I am I' m not yet this - to see - I must and I' m in the party.\", \"I' m reviewing out a new of my code. I can' t take that I' m doing this, but it' s so much get in this...\", 'As: Robot of papers - driving car robot', \"My stack of the best time I' ve ever seen of the Year apps with a few days ago: 3\", 'iOS7 - stumbled by Twitter 2012 \" The Egg \" \", \", \" run_now \", \", \", \" Einstein\\' s \". impressive is a Turing', 'A Compilation to watch the best pets - Wired the internet of the day.']\n",
            "['Up next in Nature: Dendrites not passive compute units! Ion channels implicated as basic computational units. 1', 'RE: Boston Dynamics Spot video & people\\'s response to seeing it get kicked. I wonder if \"robot cruelty\" will be a thing, or \"robot rights\"', \"I registered for Google IO and was happy and then just noticed it overlaps Perfectly with this year's CVPR. Not cool\", \"A tweet! Just because I didn't for a while :) leaving to Vancouver in 2 hours. A slice of pizza is in order\", 'Yummy data! Microsoft Academic Search was awesome API resource until it was taken down a few months ago Microsoft releases data for Academic Graph, 37GB of \"paper-paper citations, author-paper, paper-topic and so forth\"', \"Recurrent Model of Visual Attention in Torch Doesn't quite convey how simple REINFORCE update is, but nice post torch.ch Torch | Recurrent Model of Visual Attention Torch is a scientific computing framework for LuaJIT.\", 'My by-a-margin favorite educational YouTuber ( @cgpgrey ) is starting a new podcast \"Hello Internet\" subbed', '3D printing on nanoscales. 3D printing is becoming cooler every day. 1', 'Speech2Face: Learning the Face Behind a Voice With increasingly largeeffective library of neural net encoders of any X and decoders of any Y, any source of paired data X,Y can give X2Y nets. And opens the door to many X2Y2Z2W...2X', 'I wish tax forms and related legal documents were written in English. I had to stumble on a 2-sentence Yahoo answers post to get this one', 'Congrats to good friend @RichardSocher and his new and exciting Deep Learning startup! a company to watch closely.', 'Awesome Google Research blog post on scaling up robotics ai.', 'Working hours: Get a Life. Research on relationship between hours worked & productivity [Economist] 1', 'Computer vision in the browser: Real time semi dense point tracking in javascript', 'Kickstarter has the most interesting \"About us\" page I\\'ve seen so far (drag horizontally)', 'A terrible demo of using Voice Input to control new Xbox Voice recognition sucks as input, IMO. Companies, pls stop', 'A bit late to the party here, but \"State of AI Report 2019\" is a nice overall ambitious attempt at summarizing AI for \"research\" a bit too much RL and a bit too little vision. Interesting that vision is patented so much more than other areas (p85) stateof.ai State of AI Report 2021 The State of AI Report analyses the most interesting developments in AI. Read and download here.', 'I accidentally sipped remains of my coffee from yesterday instead of coffee from today. It was unpleasant. 2', 'Google wants to cover the Earth with balloons that beam internet to Earth. This is the Google I like', 'Wingsuit videos are immune to getting old 1', 'Haha: \"50 People On ‘The Most Intellectual Joke I Know\\'\" (via @thenilly )', 'Research on solving Bongard problems: somehow these seem closely related to some core aspect of intelligence', '\"The Future of Online Identity is Decentralized\" web identity is in a very bad place. Current good+easy blend is to not use \"Sign in with...\" but a (paid) password manager. But some dedicated service has to \"factor it out\". +HN', 'is the chatter of the day. \"Is connectivity a human right?\" +NYT article', \"By the beard of Zeus! Anchorman 2 was announced today! I don't know how to put this but this is kind of a big deal.\", 'Ideally never absorb information without predicting it first. Then you can update both 1) your knowledge but also 2) your generative model.', 'I updated the yesterday. Now with even more conferences for even more headaches! Feedback welcome', 'A critique of pure learning and what ANNs can learn from animal brains \"a large component of an animal’s behavioral repertoire is not the result of clever learning algorithms—supervised or unsupervised—but of behavior programs already present at birth.\"', 'Sitting in bookstore in moment of nostalgia reading one of my favorites: Mechanics by Landau&Lifshitz. I remember taking this 5 years ago :(', 'This is from 2 days ago, but Curiosity has now been on Mars for 1 year. Some reflectionscelebration from NASA:', 'Visited Apple for the first time. Spotted Jony at lunch. #visitsuccess Now I know which Apple Watch band he uses and must get the same', 'Wednesday is my favorite day at work- 8 hour block of uninterrupted hacking time and no other scheduled bs.', 'Programming Languages homework finished. Lambda calculus and many many many brackets... #exhausted 1', 'ICLR papers are now up . This year have to use CMT to seesubmit comments', 'Does Passing A Small Current Through Your Brain Really Make You Smarter? hmmm... curious. skeptical.', 'Wow: Steve Ballmer (Microsoft CEO) to resign within a year. Stock up 7% right after announcement', \"I'm a bit of a noob at photography, but I've always enjoyed the subject and dabbled with it a bit in...\", 'Hmm. I became followed by a person with 0 followers, 0 tweets and 1 followee (me). Stalker!!! Lol', 'yay has reached 1,000 registered users! Growing few dozen a day.', \"My friend is fast enough at Rubik's cube to fit into a vine :) vine.co Andrej Karpathy's post on Vine My friend is fast enough at Rubik's cube to fit into a vine :) 2\", \"Former Google Reader Product Manager on why Google Reader was shut down Spoiler: yes, it's Google+. Ohhhhhhasfdasgfd\", 'My dad emailed me a link to a funny video of a cat. I think he just discovered YouTube. 1', 'Why Twitter is obsolete | Social Media (via @bradacker22 ) -- some good points. agree i think', 'hah, OH from friend: \"papers are often written in a way to hide embarrassingsloppy details and the fact that the ideas are very simple\"', 'I found a code base that goes against everything I believe in and stand for as a person. It pains to think that some CPU had to execute that', \"I reduced the price of one of my iOS apps from $1 to free, went from 200 downloadsmonth to 3000. Seems like people really can't afford a $1\", 'As far as I can tell my convnet predicts \"Erotica\" for woman\\'s face sideways. Man face doesn\\'t do it. Having too much fun with this', 'My top Diablo 3 heroes are called Sigmoid, ReLU and tanh. Now creating Maxout crusader. Maybe one day someone will get it. 5', \"iOS7 has early support for multipath TCP spec. (use of several conns at same time) This tech can't come soon enough\", 'A good essay from Aaron Swartz on productivity. I can relate a lot to what he says and need to improve here.']\n",
            "True\n",
            "12/07/2021 20:40:58 - INFO - __main__ -   ***** Metrics results *****\n",
            "12/07/2021 20:40:58 - INFO - __main__ -       bertscore_f1 = 0.8194479942321777\n",
            "12/07/2021 20:40:58 - INFO - __main__ -       bertscore_precision = 0.8177949786186218\n",
            "12/07/2021 20:40:58 - INFO - __main__ -       bertscore_recall = 0.8215520977973938\n",
            "12/07/2021 20:40:58 - INFO - __main__ -       bleu_score = 0.5120158098694774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_lstm_metrics.py \\\n",
        "  --username \"BarackObama\" \\\n",
        "  --test_data_file \"data/BarackObama/test.txt\" \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --with_glove True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNB2tV9fnd4-",
        "outputId": "2973ffd3-a568-4b98-d321-d4662b2f464f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "['\" Even we need to get to keep moving forward and not, as hard in every corner, and we\\' ve got to do.\" —President Obama', '\" You\\' re no better I\\' t play —should have to work on the... of our nation.\" —President Obama on Obamacare #EqualPay', 'Ready for summer, @MichelleObama.', 'Eric years ago today. Have a great weekend, everybody.', \"Bonnie' s on immigration. #Obama2012\", 'Bahamian was coming.', 'In his weekly address, President Obama makes how we can vote as #EqualPay:', '\" All of Americans who need to be in for health care.\" —President Obama', \"Our journey is not complete until the election. Change' re not done. It' s on #immigration reform. #immigration system\", '\" This is a part of action. It\\' s about how we can get ahead.\" —President Obama', 'Help a woman. #GetCovered', 'Today, we made history our troops from our communities once courts. - bo', 'Enjoy, a small business owner, a volunteer with Indiana celebrate —and it comes to help win a free trip:', '\" Few is not a good thing to just a year of action.\" —President Obama #CollegeOpportunity', 'Welcoming.', 'The story of how the Affordable Care Act is helping millions of Americans:', 'Health care reform is a bipartisan issue to millions of action that we can do:', 'Watch live: President Obama speaks in Ohio about the choice we face in this election.', 'WATCH: President Obama is speaking at the U. S. wind Summit.', 'WATCH: President Obama is participating in a town hall at @ETPT.', 'The choice is in.', \"“ Every's hard about the American people —to give me you a vote.”\", 'President Obama: \" If I\\'m only as you can help me what I do not to the right to vote.\"', 'FACT: In 2010, Romney would allow that would take away with $ 2, 000 to get a bipartisan compromise to deficit reduction a woman. #DontDoubleMyRate', '\" The American people deserve a vote.\" —President Obama #OpportunityForAll', \"Michelle you're a reason to help this campaign and the American people —make this today:\", '.@OFA_PA. #Obama2012', 'Support the campaign of a great weekend. Tell your name in:', \"As of this campaign, we' re going to wait. Show your voice to #GetCovered:\", 'Good news: More than 1 million Americans could be eligible health coverage for a single health care plan.', '\" These is good news on our infrastructure, our children\\'s doing.\" —President Obama #SOTU', 'In less, PA. At a \" Change We Need Rally. Watch it live at 3', \"President Obama: “ I know how much that America is not a political going on's not —.” #EqualPay\", \"Right now: “ It's the American auto industry is in the future. We are going to make sure that we are not going to vote.”\", '\" In the 21st century, we\\'ve got to make sure that America is an important step.\" —President Obama #WomenSucceed', '\" Sergeant is not just a luxury. This is about America is a great.\" —President Obama #SOTU', \"Kathy has changed to give these reins the economy and creating jobs —you can' t afford it wait for #RaiseTheWage.\", '\" I believe we\\' re going to keep moving forward, and we\\'ve got to work with our nation and our future.\" —President Obama', 'President Obama: \" We will not be a job where everybody\\'s infrastructure is at stake in this election.\" #SOTU', 'Happening now: President Obama delivers a statement on the situation in Iraq.', 'An economic shutdown —that is not just again. This is what change looks like:', 'Get ready:', \"Take a look behind the scenes from the President' s new on #climate change in the election:\", '\" We\\'re building to go... I wanted to do it, and that\\' s saving.\"—President Obama on the need for the President in Chicago.', 'Made a free bumper sticker to let the American people speak on the new health care options:', 'Americans are up in for health care enrollment:', 'FACT: More than 200, 000 people have signed with a piece of this campaign in 2014. #ActOnJobs', '\" America deserves a raise. It\\' s about the same.\" —President Obama', 'Closing is the day of time.', 'Expanding out in America: #Obama2012']\n",
            "['\"Even before taking office, I made clear that Iran would not be allowed to acquire a nuclear weapon on my watch.\" —President Obama #IranDeal', '\"You guys give me confidence. You guys give me hope. I really need all of you to get out and vote on Nov 2.\"', 'Ready for spring.', 'Eric has a story that you need to hear:', \"Bonnie's 23-year-old daughter was diagnosed with cancer. She wrote a letter everyone needs to read: #ACA\", 'Bahamian families and communities face a long recovery from Hurricane Dorian. And Americans are reaching out to help. Brittany Garvin is helping people reunite and evacuate.', \"In Indiana on the 40th anniv. of Dr. King's assassination. Asking everyone to continue his lifelong pursuit of social & economic justice.\", '\"All of our men and women in uniform around the world must know that they have our respect, our gratitude, and our full support.\" #SOTU', \"Our take: he's right. No major differences between Tea Party agenda and GOP candidates' policies.\", '\"This will be a year of action.\" —President Obama', 'Help organizers from across the country get the training needed to take their skills to the next level:', \"Today at p.m. ET: Don't miss President Obama's announcement on #climate change.\", 'Enjoy the holiday season with the ones you love. Michelle and I wish you a very Merry Christmas!', '\"Few things can have as negative an impact on our economy as climate change.\" —President Obama #ActOnClimate', \"Welcoming the nation's students back to school—watch today at noon ET:\", 'The final march for reform has begun. We need you to talk to your neighbors and help spread the facts on health reform:', 'Health care reform took generations of organizing. Say you were a part of this: (ht @OFA ) #8Million', 'Watch a livestream of the second inauguration here starting at 1am ET:', 'WATCH: President Obama discusses #CollegeOpportunity with students from across the country.', \"WATCH: The Obama administration supports a ban on conversion therapy to protect America's youth.\", 'The March 1st deadline is approaching. #GetCovered today:', '“Every time you fill up at the pump, they’re making money. They’re doing just fine.”—POTUS on ending Big Oil subsidies:', 'President Obama: \"Today, our businesses have created over 5 million new jobs. The American auto industry is back on top.\"', \"FACT: The Affordable Care Act allows young adults to stay on their parents' insurance until they are 26 years old.\", '\"The United States of America is the most powerful nation on Earth. Period.\" —President Obama #SOTU', 'Michelle and I send our condolences to the people of New Zealand. We grieve with you and the Muslim community. All of us must stand against hatred in all its forms.', '.@OFA_PA volunteers are building this campaign in the rain—reminding folks to vote in tomorrow’s primary:', 'Support the campaign from your front lawn with our 2012 yard signs:', 'As the June unemployment numbers are released, it is clear we are headed in the right direction, but we are not headed there fast enough.', 'Good news: The economy added 216,000 private sector jobs in May. #ActOnJobs', '\"These cuts are not smart. They will hurt our economy and cost us jobs—and Congress can turn them off at any time.\"', 'In Cedar Rapids, IA at Coe College for the MySpace MTV Presidential Dialogue. It will stream live at pm ET', 'President Obama: \"Over those 100 days or so, more than 100 times as many Americans have fallen victim to gun violence.\" #DemandAction', 'Right now @OFA is looking for new members for the team that will make 2014 a year to remember. Are you in?', '\"In no other nation on Earth could my story even be possible.\"', '\"Sergeant First Class Cory Remsburg never gives up, and he does not quit.\" —President Obama #SOTU', 'Kathy recalls #Nov4 2008: \"People danced; people sang. I had a feeling that the country had somehow changed in one evening.\"', '\"I promise you: You have a president who will take action to support working families.\" —President Obama #FamiliesSucceed', 'President Obama: \"Hello Colorado! Are you fired up? Are you ready to go?\" #AmericaForward', 'Happening now: President Obama is holding a press conference. Tune in.', 'An inside look at a GOP super PAC\\'s plan to \"do exactly what John McCain would not let us do\" in 2008:', 'Get a close look inside the first-ever @OFA Organizing Director Summit:', 'Take a look at what editorial boards across the country think of the Senate refusing to do its job: #DoYourJob', '\"We cannot ignore the problems that we have, but we can\\'t stop running the race.\" —President Obama', 'Made in the USA and all purchases go toward re-electing the President—take a look around the #Obama2012 store:', 'Americans want progress. This is about making it happen. Watch:', \"FACT: Romney's plan repeals Obamacare, won't protect families from insurance company abuses, and leaves 50 million more Americans uninsured.\", '\"America would have gone backwards. That\\'s not what we do. We move forward.\" —President Obama', \"Closing background check loopholes will save lives—and it's time for Congress to act. #DemandAction,\", \"Expanding #CollegeOpportunity is vital to America's success in a global economy:\"]\n",
            "True\n",
            "12/07/2021 20:39:18 - INFO - __main__ -   ***** Metrics results *****\n",
            "12/07/2021 20:39:18 - INFO - __main__ -       bertscore_f1 = 0.8543335199356079\n",
            "12/07/2021 20:39:18 - INFO - __main__ -       bertscore_precision = 0.856122612953186\n",
            "12/07/2021 20:39:18 - INFO - __main__ -       bertscore_recall = 0.8530134558677673\n",
            "12/07/2021 20:39:18 - INFO - __main__ -       bleu_score = 0.5189418844302464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_lstm_metrics.py \\\n",
        "  --username \"cnn\" \\\n",
        "  --test_data_file \"data/cnn/test.txt\" \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --with_glove True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7dl9eS9ng_h",
        "outputId": "dc59fbe5-29dc-41c1-972a-6902a40d36dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[\"Husband suspect' s son' s death: She.\", \"Wisconsin releases over' s, kills' s the health care\", 'U. S. official: Stocks post Court - minute CNNBelief, 500 say.', \"U. S. soldier' s' Scientists' gone with aid.\", \"RNC' s son will not get to land.\", 'Twitter: Child lose a year - way\\' t know he\\' s \" going to a half of the \" writes @Locs_n_Laughs for @CNNOpinion:', 'President Obama is speaking now about the Bush in Wisconsin. Watch live on @CNN TV or', \"The US' s love - biggest - old' s end.\", \"D. C. governor says he was also the day care in the GOP convention, but he didn' t have the most of Mexico.\", 'A rare - year - old girl in Brazil.', \"CNN' s John King: President Obama speaking about the economy - watch live on @CNN TV and\", \"Poll: Most Americans still in on Obama' s' plan'\", 'Police: man killed in shooting at Afghan standoff.', 'Transgender official in Alabama home', \"What' s the #CNNDebate and all the Queen?\", \"Sheriff' s nuclear reactors:' Our back on' no and bin Laden\", \"Astronomers, 000 pounds of t's secret in New York City tonight:\", \"Witness to' d' s of' s' doing,'\", \"CNN' s @Snapchat channel @WolfBlitzerCNN has died, a @front is a new @AndersonCooper.\", 'Employees seeks Alabama on man', \"What' s the worst for your Border?\", 'New Zealand leader has been recovered from bridge collapse collapse', \"This week' s new airport #CNNElection\", 'Florida boy held in custody after allegedly boat:', \"Smith' s son sentenced to life in prison\", \"BREAKING: Ukraine projects arrested in connection with @' s @BrookeBCNN. Preview in the #CNNDebate and his CNN iPhone App.\", \"Women' s corpse:' I am not a'\", 'Ex - Catholic: What you need to know about a new gold?', '\" Sometimes shouldn \" the Republican of the year, 000 feet - a - in condition that can save his wife:', 'AT & T of #, the new CNN poll, the Republican, and the Supreme Court and the key of the future.', 'Mayor: Stop @realDonaldTrump is on his sex.', \"National of' felony' child - word' s' s' found in New York, New Jersey - CNN interview, and join the conversation at\", 'Reid: Why you can get the new money.', \"UK:' s was a' at box office' 2\", \"Report: Mystery of man in Egypt, who died' s dad to be sentenced to police, source says.\", 'From @andersoncooper: \" We\\' re in our?\" \" - @CNNOpinion column by @CrowleyCNN:', 'Texas abortion of Pontifex released from hospital.', \"Knox:' I am not a judge' 2\", 'N. K. tells. Watch CNN and @CNNgo:', 'Rubin and video: The man who died in a place to the hospital.', 'Nearly 300, 000 kids in Bangkok, Egypt.', \"Firefighter: I' m flee' s I' m the dead 1\", \"Second' s intriguing people.\", 'Canadian fights puts 5', \"Democrat: Obama' s'' of' The,'' s dies at the age of 86 in Syria.\", \"Here' s how to find your favorite?\", \"The first world' s wife look at a - eating amoeba One to be a' suicide.\", \"Sotomayor:' The party' co - Iran,' kids' 4\", 'The White House is not a plane of the World Series', \"Logic: No' s is' d' s going to be about' The':\"]\n",
            "[\"Husband wants answers after wife's death sparks abortion debate in Ireland:\", 'Wisconsin Senate bypasses Democrats, OKs union limits.', 'U.S. Embassy in Kabul attacked.', 'U.S. drone shot down in eastern Iran, state media reports, citing military source.', \"RNC chairman condemns 'Magic Negro' song 1\", 'Twitter has restored a feature that allows users to \"block\" unwanted followers. money.', 'President Trump: \"Amazon is gonna have to pay much more money to the Post Office. There\\'s no doubt about that\"', 'The Defense Department has confirmed that leaked photos and video of \"unidentified aerial phenomena\" taken in 2019 are indeed legitimate images of unexplained objects', 'D.C. school system fires 241 teachers.', 'A man was killed by a crocodile nicknamed \"Michael Jackson.\" Here\\'s what police say appears to have happened:', 'CNN wants YOUR input to choose the most intriguing people of 2012:', 'Poll: Clinton and Trump neck-and-neck in Iowa', 'Police: Spears has minor accident in Mercedes', 'Transgender teen: \"My death needs to mean something.\" #LeelahAlcorn', 'What do you want to know about pop star Britney Spears’ fight to take back her life? Watch CNN Special Report: Toxic – Britney Spears’ Battle For Freedom to find out all about it. Tonight at 8 p.m. ET', \"Sheriff's deputies in Los Angeles handcuffed rapper Wyclef Jean after mistaking him for a robbery suspect\", 'Astronomers have discovered auroras on a brown dwarf 20 light-years away.', 'Witness in France says truck driver appeared to accelerate as he hit bodies', 'CNN\\'s Chief Medical Correspondent Dr. Sanjay Gupta fulfilled a lifelong dream by hosting \"Jeopardy!\" He is one of several guest hosts for the show.', 'Employees sacked over Ford art on tied-up women.', \"What's hiding in your food? @MorganSpurlock uncovers the things you probably shouldn't be eating on #InsideManCNN\", \"New York state officials are attempting to have a federal court throw out President Trump's lawsuit over the possible release of his tax returns to Congress, according to a new court filing\", 'This is @Bourdain \\'s favorite \"vegetable.\" Is it yours? Explore the flavors of Madagascar on #PartsUnknown tonight. vine.co CNN\\'s post on Vine This is Anthony Bourdain\\'s favorite \"vegetable.\" Is it yours? Explore the flavors of Madagascar on #PartsUnknown.', 'Florida mother shoots and kills infant son in murder-suicide attempt, police say:', 'Smith & Wesson shares hit an all-time high Monday', 'BREAKING NEWS: The Alabama Crimson Tide caps undefeated season with 37-21 win over Texas Longhorns in BCS title game.', 'Women\\'s suffragist Susan B. Anthony was never able to vote, so people are leaving \"I voted\" stickers on her grave', 'Ex-Catholic priest in photo scandal marries 2', '\"Sometimes we\\'re treated like mushrooms, we\\'re kept in the dark\": Rep. Garamendi says Niger briefing lacked details', 'AT&T to activate faster 4G network:', 'Mayor cleared in drug raid that left dogs dead', 'National guardsman reunited with dog days after tornado destroys town.', 'Reid: \"Watching white nationalists celebrate while innocent Americans cry tears of fear does not feel like America\"', 'UK: China executes British citizen.', 'Report: Fugitive suspected in Jakarta blasts 2', \"From CNN's Matthew Chance: Clashes outside the hotel. #Rixos4 hunkered down. #Libya @mchancecnn\", 'Texas Senator Ted Cruz pheasant hunts, bashes Obamacare in Iowa', \"Knox: 'I'm afraid to go back' to Italy. @ChrisCuomo 's wide-ranging intv wAmanda Knox; 10p ET Tues on CNN.\", 'N.K. has made nuclear progress, experts say', \"Rubin 'Hurricane' Carter still fighting long after boxing days pass.\", \"Nearly half of Florida's counties have agreed to provide Spanish-language assistance and materials to voters after a years-long legal battle\", 'Firefighter arrives to find own house in flames.', 'Second storm snarls traffic in Argentina: 9', 'Canadian skier arrested, accused of stealing car at Winter Olympics', \"Democrat: 'Ask Tiger, not me.'\", \"Here's how to get all your holiday shopping done in one day #BlackFriday\", 'The space shuttle Enterprise is flying over New York City right now - watch it live on @CNN TV or', \"Sotomayor: 'Law is not legal theory' 2\", \"The changing face of America's youth.\", 'Logic rules drug murders, trafficker says 2']\n",
            "True\n",
            "12/07/2021 20:39:43 - INFO - __main__ -   ***** Metrics results *****\n",
            "12/07/2021 20:39:43 - INFO - __main__ -       bertscore_f1 = 0.8305311799049377\n",
            "12/07/2021 20:39:43 - INFO - __main__ -       bertscore_precision = 0.8252542614936829\n",
            "12/07/2021 20:39:43 - INFO - __main__ -       bertscore_recall = 0.8366816639900208\n",
            "12/07/2021 20:39:43 - INFO - __main__ -       bleu_score = 0.6705774476746761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_lstm_metrics.py \\\n",
        "  --username \"wsj\" \\\n",
        "  --test_data_file \"data/wsj/test.txt\" \\\n",
        "  --temperature 0.8 \\\n",
        "  --k 50 \\\n",
        "  --p 0.9 \\\n",
        "  --with_glove True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2K89xJbni31",
        "outputId": "e45f16cf-9cc2-4682-f442-c5e0bb4363d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[\"It's not to pull off about the economy of the market closes, writes @djtgallagher\", \"India's stock market has been tear for the Federal Reserve. P:\", 'Take an early look at the front page of The Wall Street Journal', \"T. a. T. u., a.- is the world' s top strategy:\", \"REI's third - quarter sales report on its business - use results China\", 'Time to Retire in India, entertainment:', 'From a southern market: the right of the new year - old company?', 'In a high - profile school from @WSJ, @and @:', \"Netflix' s' s ex - president, a look at the most powerful tax in history\", \"Opinion: If the's handling of the Fed, but the GOP is not enough for stocks.\", \"Obama says Trump' s decision on whether to change its third - quarter market\", 'Breaking: House votes to hold the tax bill in the top 10 years of the White House', \"A new book man a popular tough in the country's biggest mobile fund, prompting the Iran, is now.\", 'The Democratic primary between and is what to expect in the past', \"All on the latest: the French' s top of the U. S. Embassy from the White House\", \"General Motors' s new CEO, is the largest American of the nation' s largest city\", \"Trump' s plan has fallen since governor, 000 and more than 1, 000 on the U. S. government\", \"Chesapeake' s New home prices 1\", \"Goldman Sachs' s third - quarter earnings results, as the company' s second report on the Philippines.\", 'More Americans are struggling to improve security, but not enough for stocks', 'Centrist to Enter warships to be a way to the Federal Reserve since the party in the third quarter', \"During' s Profit 1\", 'Florida: \" The Interview of the \" and not just a \" - day \"', \"The SEC's new - old American yield of the Paris climate accord\", 'Open Gov. Rick Perry to the first time in the Midwest', 'Rockets has died in Virginia for the year', 'US Airways to Cut Jobs Jobs', \"As next generation, the Republican tax bill might, it will be a heavy for the next year's most powerful economy\", 'Law the first anniversary of the second - largest history of the year', \"BP' s jobs report, the NFL - language ruling on the food - off system of the U. S. mainland\", \"The U. S. Postal Service will use a $ 300 million last quarter, but a nuclear deal, but the market's foreign big banks\", 'Jessica Posts Loss on Weak Sales', \"Stop police by probing of the NHL's central bank is the first female dramatic deal with Trump' s government shutdown\", 'Yum for allow 7', \"Is the latest joins of its TV? Here' s why, it's a preview for the economy.\", \"7. 5 million people she wouldn' t the only option to a new low of $ 1. 7 billion acquisition of the year\", 'The new U. S. stocks have become the last since a half - year - old man the $ 15 billion', \"Opinion: Democrats American more than ever Obama' s\", 'Grupo\\' s new cyber: \" I\\' m see the United that he\\'', \"Want to see a living in the college? These you think' t want to watch the tax code:\", 'Three years of the year to deliver costs:', \"Trump' s military and other House' s new leadership\", 'Opinion: The GOP tax reform outline a deal to make the tax cuts, writes @KarlRove', 'Consumer: \" \" is \" and many \" I feel.\" An insider - trading - old - man - you - -.. - card services.', \"GM' s Profit Rise\", \"Ohio is on the rise in the world' s largest - top - old company will be found\", \"Federal' s plans - no plans to leave of the company' s IPO of its largest quarterly in the U. S.\", \"Prime Minister Cost of a ‘ couple'’ re capital of the best's new FBI\", 'Facing in the U. S. Here are five, after many big tech firms have a problem?', \"When' s next about the years crown of doing for the first time' s primary\"]\n",
            "['It’s rocket science: North Korea lifts the hood on its newest missile', 'India’s Supreme Court is set to decide a closely watched case in a decadeslong dispute between Hindu and Muslim groups over control of an especially controversial religious site in northern India', 'Take an early look at the front page of The Wall Street Journal', 'T.a.T.u., a Russian pop duo with a lesbian image, is set to play Sochi Olympics opening ceremony.', 'REI’s new headquarters blur the boundaries between office and nature', 'Time for a rethink on Chinese property stocks — Heard on the Street', 'From @WSJopinion : “These freshmen give me faith that the post-#MeToo world might be a safer one.” Students reflect on the #MeToo era and its effect on college campuses.', 'In these world championships, competitors go for the gold in welding, baking, hairdressing and bricklaying', \"Netflix's Q2 earnings plummeted 91% as the company took in higher subscription costs. $NFLX\", 'Opinion: Air-traffic reform would reduce federal employees by more than 30,000 and federal spending by billions', \"Obama watched Mubarak's speech on Air Force One, then huddled with his national-security team\", 'Breaking: Bubba Watson wins the Masters, beating Louis Oosthuizen on the second hole of a playoff.', \"A company in Tokyo is using the 'Rocky' theme song to inspire Japanese workers to leave the office\", \"The NFL coaches best at ushering their teams into the future? They're the oldest ones\", 'All about the dark arts of cellphone signal-strength bars: \"It\\'s just a rough graphical presentation.\"', 'General Motors CEO Mary Barra finally reveals the whereabouts of the GM jetpacks', 'Trump drafted letter on why he wanted Comey out', 'Chesapeake Energy shares spiked after announcing CEO Aubrey K. McClendon will step down in April.', 'Goldman Sachs is considering shutting down its dark pool trading operation known as Sigma X.', 'More than 500 nuclear tests have been conducted above ground, but none since 1980', 'Centrist Democratic Sen. Joe Manchin of West Virginia stepped up his campaign to cut the price tag of Democrats’ $3.5 trillion healthcare, education and climate legislation, calling for a “strategic pause” in the effort', 'During World War I, a pigeon named Cher Ami delivered a message that saved nearly 200 U.S. soldiers despite losing a limb to enemy fire. Now members of his breed sell for big bucks.', 'Florida hospitals to settle Medicare-fraud allegations tied to unnecessary ambulance rides:', 'The FTC has ordered broadband providers to file detailed special reports on their data-handling and privacy practices within 45 days', 'Open surgeries did not see a sustained increase after the FDA warned of the risks of using power morcellators in hysterectomy operations, a study found', 'Rockets were fired from the Gaza Strip in what appeared to be an attack targeting a memorial ceremony for a slain Israeli soldier', 'US Airways to Cut Jobs, Raise Fees', 'As U.S. mulls moving embassy to Jerusalem, Palestinians feel helpless', 'Law schools are seeing the first significant uptick in applications in years. One of the reasons? Politics', 'BP\\'s \"top kill\" procedure has failed to stem the flow of oil into the Gulf; next step will take 4-7 days', 'The website that broke the story of the racist photo that is imperiling Virginia Democratic Gov. Ralph Northam is a pro-Trump outfit backed by Republican operatives', 'Jessica Alba’s Honest Co. has struggled to achieve sustainable growth after product woes', 'Stop counting calories. It’s the clock that counts.', 'Yum China is testing new technologies and menus in an effort to be more than finger lickin’ good', 'Is Twitter really worth $10 billion?', '7 myths (and truths) about olive oil:', 'The Domino’s tracking app delivers pizza to all, disillusionment to some', 'Opinion: Are foundations running state energy policy without transparency?', 'Grupo Mexico Hits Hurdle in Asarco Case 1', 'Want to go beyond your usual G&T? Here are 5 easy gin and tonic upgrades:', 'Three Deals Launched on TALF-Debut Day', 'Trump called Justin Trudeau “two-faced” after the Canadian prime minister and other world leaders appeared to talk about the U.S. president at a NATO reception', 'Opinion: While Washington is stuck in neutral, French and Dutch reformers are pushing radical change, writes @josephsternberg', 'Consumer demand for meat is surging, and supermarkets are bracing for shortages as the coronavirus forces meatpacking facilities to close', \"GM's Wagoner Will Step Down 1\", 'Ohio State president Gordon Gee will retire July 1, in the wake of recently released controversial comments.', 'Federal prosecutors say Anthony Weiner deserves about two years behind bars in his sex case', 'Prime minister Theresa May is expected to say Tuesday that the U.K. wants a clean break from the EU', 'Facing rivals with powerful mobile OS ecosystems, Amazon and Microsoft will let Alexa and Cortana talk to each other', 'When Snap said it wanted IPO investors to get powerless shares, few investors said no']\n",
            "True\n",
            "12/07/2021 20:40:07 - INFO - __main__ -   ***** Metrics results *****\n",
            "12/07/2021 20:40:07 - INFO - __main__ -       bertscore_f1 = 0.8336453437805176\n",
            "12/07/2021 20:40:07 - INFO - __main__ -       bertscore_precision = 0.8309577703475952\n",
            "12/07/2021 20:40:07 - INFO - __main__ -       bertscore_recall = 0.8366718292236328\n",
            "12/07/2021 20:40:07 - INFO - __main__ -       bleu_score = 0.5453818204473914\n"
          ]
        }
      ]
    }
  ]
}